{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:17.272622Z",
     "start_time": "2025-04-06T20:23:17.270584Z"
    }
   },
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "from crewai_tools import SerperDevTool"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:17.284184Z",
     "start_time": "2025-04-06T20:23:17.282392Z"
    }
   },
   "cell_type": "code",
   "source": "REVISION_ROUNDS = 5",
   "id": "8e744fc81baaf46",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the Research Topic + Additional Papers",
   "id": "e0021fac457bc8fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:17.300213Z",
     "start_time": "2025-04-06T20:23:17.295715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def append_to_summary_file(text, file_path=\"summaries/intermediate_steps.txt\"):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(text + \"\\n\\n\")\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def parse_serper_response(response_str):\n",
    "    \"\"\"\n",
    "    Parse the literal string output from Serper.\n",
    "    Assumes segments are separated by '---' and each segment contains lines starting with \"Title:\" and \"Snippet:\".\n",
    "    Returns a list of tuples (title, snippet).\n",
    "    \"\"\"\n",
    "    segments = response_str.split('---')\n",
    "    papers = []\n",
    "    for seg in segments:\n",
    "        seg = seg.strip()\n",
    "        if not seg:\n",
    "            continue\n",
    "        title = \"\"\n",
    "        snippet = \"\"\n",
    "        for line in seg.split('\\n'):\n",
    "            if line.startswith(\"Title:\"):\n",
    "                title = line[len(\"Title:\"):].strip()\n",
    "            elif line.startswith(\"Snippet:\"):\n",
    "                snippet = line[len(\"Snippet:\"):].strip()\n",
    "        if title or snippet:\n",
    "            papers.append((title, snippet))\n",
    "    return papers\n",
    "\n",
    "def get_additional_google_scholar_papers(query, serper):\n",
    "    # Call serper; its output is a literal string.\n",
    "    response_str = serper.run(search_query=query)\n",
    "    parsed = parse_serper_response(response_str)\n",
    "    results_text = \"\"\n",
    "    for i, (title, snippet) in enumerate(parsed):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        results_text += f\"Title: {title}\\nSnippet: {snippet}\\n\\n\"\n",
    "    if not results_text.strip():\n",
    "        results_text = \"No additional papers found from Google Scholar.\"\n",
    "    return results_text"
   ],
   "id": "b3419df31c51d149",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:17.310374Z",
     "start_time": "2025-04-06T20:23:17.306849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def escape_latex(text):\n",
    "    # Escape common characters (extend as needed).\n",
    "    return text.replace(\"&\", r\"\\&\")\n",
    "\n",
    "def iterative_revision(text, section_name):\n",
    "    \"\"\"Iteratively revise the given text for REVISION_ROUNDS rounds.\"\"\"\n",
    "    revised_text = text\n",
    "    for round in range(REVISION_ROUNDS):\n",
    "        prompt = (\n",
    "            f\"Revise the following {section_name} text to improve clarity, structure, and academic tone. \"\n",
    "            \"Output only the final text (no additional commentary).\\n\\n\"\n",
    "            f\"{revised_text}\\n\"\n",
    "            f\"Revision Round: {round+1}\"\n",
    "        )\n",
    "        revised_text = llm.predict(prompt)\n",
    "        append_to_summary_file(f\"Revision Round {round+1} for {section_name}:\\n{revised_text}\")\n",
    "    return revised_text\n",
    "\n",
    "def generate_section_latex(section_name, text):\n",
    "    \"\"\"\n",
    "    Convert the given section text into well-formatted LaTeX code.\n",
    "    Instruct the LLM to make full use of LaTeX formatting options (e.g. enumerate, itemize, etc.).\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Convert the following text for the '{section_name}' section of a research proposal into well-formatted LaTeX code. \"\n",
    "        \"Use advanced LaTeX formatting (e.g., \\\\section, \\\\subsection, \\\\textbf, \\\\begin{enumerate} ... \\\\end{enumerate}, etc.) as appropriate. \"\n",
    "        \"Output only the LaTeX code.\\n\\nText:\\n{text}\"\n",
    "    )\n",
    "    latex_section = llm.predict(prompt)\n",
    "    # Optionally, apply iterative revision on the LaTeX code\n",
    "    latex_section = iterative_revision(latex_section, f\"{section_name} LaTeX Section\")\n",
    "    return latex_section"
   ],
   "id": "169e59083f9fce34",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:17.332044Z",
     "start_time": "2025-04-06T20:23:17.316707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "serper = SerperDevTool(api_key=os.getenv(\"SERPER_API_KEY\"))"
   ],
   "id": "7f0802ff93a37d08",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:17.341356Z",
     "start_time": "2025-04-06T20:23:17.338612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "research_topic = (\n",
    "    \"Developing a Retrieval-Augmented Generation (RAG) LLM for retrieval of medical papers, \"\n",
    "    \"enabling a centralized vector store to mass pull papers, articles, and journals.\"\n",
    ")\n",
    "print(f\"Selected Research Topic:\\n{research_topic}\")\n",
    "append_to_summary_file(f\"Selected Research Topic:\\n{research_topic}\")"
   ],
   "id": "43c0066b16e24ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Research Topic:\n",
      "Developing a Retrieval-Augmented Generation (RAG) LLM for retrieval of medical papers, enabling a centralized vector store to mass pull papers, articles, and journals.\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:18.003541Z",
     "start_time": "2025-04-06T20:23:17.362046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gs_query = \"RAG LLM retrieval of medical papers centralized vector store\"\n",
    "additional_papers = get_additional_google_scholar_papers(gs_query, serper)\n",
    "print(\"Additional Google Scholar Papers:\\n\", additional_papers)\n",
    "append_to_summary_file(f\"Additional Google Scholar Papers:\\n{additional_papers}\")"
   ],
   "id": "75c4d7a23acd45bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Search the internet\n",
      "Additional Google Scholar Papers:\n",
      " Title: \n",
      "Snippet: RAG enhances LLM's capabilities by giving access to different information sources in real-time and seamlessly integrating them with processing.\n",
      "\n",
      "Title: Developing Retrieval Augmented Generation (RAG) based LLM ...\n",
      "Snippet: This paper presents an experience report on the development of Retrieval Augmented Generation (RAG) systems using PDF documents as the primary data source.\n",
      "\n",
      "Title: Retrieval-augmented generation for generative artificial intelligence ...\n",
      "Snippet: Retrieval-augmented generation (RAG) enables models to generate more reliable content by leveraging the retrieval of external knowledge.\n",
      "\n",
      "Title: Evaluating Medical Retrieval-Augmented Generation (RAG) with ...\n",
      "Snippet: In this overview, we'll explore RAG's growing role in healthcare, focusing on its potential to transform applications like drug discovery and clinical trials.\n",
      "\n",
      "Title: What is retrieval-augmented generation? - Red Hat\n",
      "Snippet: Retrieval-augmented generation (RAG) links external resources to an LLM to enhance a generative AI model's output accuracy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Co-Thinking For Proposal Development",
   "id": "c5e03363641317de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:24.576253Z",
     "start_time": "2025-04-06T20:23:18.017104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_brainstorm = (\n",
    "    f\"Brainstorm at least 3 innovative research ideas for applying Gen AI to develop a RAG LLM for retrieval of medical papers. \"\n",
    "    \"Consider aspects like a centralized vector store, mass retrieval, and integration with academic databases. \"\n",
    "    \"Provide brief descriptions for each idea.\"\n",
    ")\n",
    "ideas = llm.predict(prompt_brainstorm)\n",
    "print(\"Brainstormed Ideas:\\n\", ideas)\n",
    "append_to_summary_file(f\"Brainstormed Ideas:\\n{ideas}\")"
   ],
   "id": "efeeb67513c0ab3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainstormed Ideas:\n",
      " 1. **Centralized Vector Store with Dynamic Updating:**\n",
      "   Develop a centralized vector store that continuously updates its embeddings based on the latest medical research papers. This system would use Gen AI to automatically parse new publications, extract key concepts, and update the vector representations in real-time. By integrating with academic databases like PubMed and arXiv, the system ensures that the most recent and relevant information is always available for retrieval. This dynamic updating mechanism would allow researchers to access the latest findings and trends in medical research efficiently.\n",
      "\n",
      "2. **Mass Retrieval with Contextual Relevance Filtering:**\n",
      "   Implement a mass retrieval system that leverages Gen AI to filter and rank medical papers based on contextual relevance to specific research queries. This system would use a combination of semantic search and contextual analysis to understand the nuances of a researcher's query and retrieve papers that are not only topically relevant but also contextually aligned with the researcher's specific focus. By integrating with academic databases, the system can access a vast array of papers and provide a curated list that meets the precise needs of the researcher.\n",
      "\n",
      "3. **Personalized Research Assistant with Adaptive Learning:**\n",
      "   Create a personalized research assistant powered by Gen AI that learns and adapts to a researcher's preferences and areas of interest over time. This assistant would use a centralized vector store to retrieve medical papers and provide recommendations based on the researcher's past interactions and feedback. By integrating with academic databases, the assistant can offer a comprehensive view of the research landscape, highlighting papers that align with the researcher's evolving interests and suggesting new areas of exploration. The adaptive learning component ensures that the assistant becomes more effective and personalized with continued use.\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:26.315141Z",
     "start_time": "2025-04-06T20:23:24.583782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_critique = (\n",
    "    f\"Critique the following research ideas for developing a RAG LLM for retrieval of medical papers. \"\n",
    "    \"Evaluate each idea on feasibility, originality, and potential impact with scores (1–5) and brief justifications.\\n\\nIdeas:\\n{ideas}\\n\"\n",
    ")\n",
    "idea_critique = llm.predict(prompt_critique)\n",
    "print(\"Idea Critiques:\\n\", idea_critique)\n",
    "append_to_summary_file(f\"Idea Critiques:\\n{idea_critique}\")"
   ],
   "id": "7d20d22b426c04d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idea Critiques:\n",
      " To provide a critique of the research ideas for developing a Retrieval-Augmented Generation (RAG) Language Model (LLM) for the retrieval of medical papers, I would need to see the specific ideas you are referring to. Please provide the list of ideas so I can evaluate them based on feasibility, originality, and potential impact.\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:35.090154Z",
     "start_time": "2025-04-06T20:23:26.340090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_gaps = (\n",
    "    f\"Based on academic literature, identify the key research gaps related to developing a RAG LLM for retrieval of medical papers. \"\n",
    "    \"Focus on limitations in current retrieval systems, vector store challenges, and integrating diverse academic sources.\"\n",
    ")\n",
    "research_gaps = llm.predict(prompt_gaps)\n",
    "print(\"Identified Research Gaps:\\n\", research_gaps)\n",
    "append_to_summary_file(f\"Identified Research Gaps:\\n{research_gaps}\")"
   ],
   "id": "7d75453360be5a9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Research Gaps:\n",
      " Developing a Retrieval-Augmented Generation (RAG) Language Model (LLM) for the retrieval of medical papers involves several complex challenges and research gaps. Based on academic literature, here are some key areas where further research is needed:\n",
      "\n",
      "1. **Limitations in Current Retrieval Systems:**\n",
      "   - **Precision and Recall Trade-offs:** Current retrieval systems often struggle to balance precision and recall, especially in the medical domain where the specificity of information is crucial. Research is needed to develop models that can maintain high precision without sacrificing recall.\n",
      "   - **Contextual Understanding:** Many retrieval systems lack the ability to understand the nuanced context of medical queries, which can lead to irrelevant or incomplete results. Enhancing contextual understanding through improved natural language processing techniques is a significant research gap.\n",
      "   - **Handling Ambiguity and Synonyms:** Medical terminology is complex and often includes synonyms and ambiguous terms. Current systems may not effectively handle these variations, leading to missed relevant documents. Developing more robust synonym recognition and disambiguation methods is essential.\n",
      "\n",
      "2. **Vector Store Challenges:**\n",
      "   - **Scalability and Efficiency:** As the volume of medical literature grows, vector stores must efficiently scale to handle large datasets. Research is needed to improve the scalability and efficiency of vector storage and retrieval mechanisms.\n",
      "   - **Dynamic Updates:** Medical knowledge is constantly evolving, requiring vector stores to be updated frequently. Developing methods for dynamic updates without significant downtime or loss of performance is a critical challenge.\n",
      "   - **Semantic Search Capabilities:** Enhancing the semantic search capabilities of vector stores to better capture the meaning and context of medical queries and documents is an ongoing research area.\n",
      "\n",
      "3. **Integrating Diverse Academic Sources:**\n",
      "   - **Heterogeneity of Data Sources:** Medical papers come from a variety of sources with different formats, standards, and quality levels. Integrating these diverse sources into a cohesive retrieval system is challenging. Research is needed to develop methods for standardizing and harmonizing data from heterogeneous sources.\n",
      "   - **Cross-Disciplinary Integration:** Medical research often intersects with other fields such as biology, chemistry, and pharmacology. Developing systems that can effectively integrate and retrieve information across these disciplines is a significant research gap.\n",
      "   - **Bias and Fairness:** Ensuring that retrieval systems do not propagate biases present in the source data is crucial. Research is needed to identify and mitigate biases in the integration of diverse academic sources.\n",
      "\n",
      "4. **Evaluation and Benchmarking:**\n",
      "   - **Standardized Evaluation Metrics:** There is a lack of standardized metrics for evaluating the performance of RAG LLMs in the medical domain. Developing comprehensive evaluation frameworks that consider the unique challenges of medical information retrieval is necessary.\n",
      "   - **User-Centric Evaluation:** Understanding how medical professionals interact with retrieval systems and incorporating user feedback into system design and evaluation is an important area for research.\n",
      "\n",
      "Addressing these research gaps requires a multidisciplinary approach, combining advances in machine learning, natural language processing, information retrieval, and domain-specific expertise in medicine.\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:43.280976Z",
     "start_time": "2025-04-06T20:23:35.097695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_structure = (\n",
    "    f\"Generate a draft research proposal structure for the topic:\\n'{research_topic}'\\n\"\n",
    "    \"Incorporate the following:\\n\"\n",
    "    f\"Research Ideas:\\n{ideas}\\n\\n\"\n",
    "    f\"Research Gaps:\\n{research_gaps}\\n\\n\"\n",
    "    \"The structure should include the following sections:\\n\"\n",
    "    \"Title, Abstract (150–250 words), Background & Literature Review, Problem Statement & Research Gap, \"\n",
    "    \"Proposed Gen AI Approach, Expected Impact in Healthcare, Limitations or Ethical Considerations, and References.\"\n",
    ")\n",
    "proposal_structure = llm.predict(prompt_structure)\n",
    "print(\"Draft Proposal Structure:\\n\", proposal_structure)\n",
    "append_to_summary_file(f\"Draft Proposal Structure:\\n{proposal_structure}\")"
   ],
   "id": "95d4fb179b5b5baa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft Proposal Structure:\n",
      " **Title:**\n",
      "Developing a Retrieval-Augmented Generation (RAG) Language Model for Efficient Retrieval of Medical Papers Using a Centralized Vector Store\n",
      "\n",
      "**Abstract:**\n",
      "The rapid growth of medical literature presents a significant challenge for researchers seeking to stay informed about the latest developments. This research proposal outlines the development of a Retrieval-Augmented Generation (RAG) Language Model designed to enhance the retrieval of medical papers through a centralized vector store. The proposed system will dynamically update its embeddings with the latest research, leverage Gen AI for contextual relevance filtering, and offer a personalized research assistant with adaptive learning capabilities. By addressing key research gaps such as precision-recall trade-offs, contextual understanding, and integration of diverse academic sources, this project aims to improve the efficiency and accuracy of medical information retrieval. The expected impact includes streamlined access to relevant medical literature, enhanced research productivity, and informed decision-making in healthcare. Ethical considerations, including data privacy and bias mitigation, will be integral to the system's design and implementation.\n",
      "\n",
      "**Background & Literature Review:**\n",
      "- Overview of current retrieval systems in the medical domain and their limitations.\n",
      "- Examination of existing vector store technologies and their application in medical literature retrieval.\n",
      "- Review of Gen AI advancements in natural language processing and their potential to enhance contextual understanding and relevance filtering.\n",
      "- Discussion of the challenges in integrating diverse academic sources and the importance of cross-disciplinary research in medicine.\n",
      "\n",
      "**Problem Statement & Research Gap:**\n",
      "- Identification of the precision and recall trade-offs in current retrieval systems and the need for improved contextual understanding.\n",
      "- Challenges in handling medical terminology, synonyms, and ambiguity.\n",
      "- Scalability and efficiency issues in vector stores, particularly with dynamic updates.\n",
      "- Difficulties in integrating heterogeneous data sources and ensuring bias and fairness in retrieval systems.\n",
      "- Lack of standardized evaluation metrics and user-centric evaluation approaches in the medical domain.\n",
      "\n",
      "**Proposed Gen AI Approach:**\n",
      "1. **Centralized Vector Store with Dynamic Updating:**\n",
      "   - Development of a vector store that continuously updates embeddings using Gen AI to parse new publications and extract key concepts.\n",
      "   - Integration with academic databases like PubMed and arXiv for real-time updates.\n",
      "\n",
      "2. **Mass Retrieval with Contextual Relevance Filtering:**\n",
      "   - Implementation of a retrieval system that uses semantic search and contextual analysis to filter and rank papers based on research queries.\n",
      "   - Use of Gen AI to enhance the understanding of query nuances and improve retrieval accuracy.\n",
      "\n",
      "3. **Personalized Research Assistant with Adaptive Learning:**\n",
      "   - Creation of a Gen AI-powered assistant that adapts to a researcher's preferences and areas of interest.\n",
      "   - Utilization of the centralized vector store for personalized recommendations and exploration of new research areas.\n",
      "\n",
      "**Expected Impact in Healthcare:**\n",
      "- Improved access to the latest medical research, facilitating evidence-based decision-making.\n",
      "- Enhanced research productivity through efficient retrieval of relevant literature.\n",
      "- Support for interdisciplinary research by integrating diverse academic sources.\n",
      "- Contribution to the development of more effective and personalized healthcare solutions.\n",
      "\n",
      "**Limitations or Ethical Considerations:**\n",
      "- Addressing data privacy concerns and ensuring compliance with relevant regulations.\n",
      "- Mitigating biases in retrieval systems to ensure fair and equitable access to information.\n",
      "- Consideration of the ethical implications of AI-driven recommendations in medical research.\n",
      "\n",
      "**References:**\n",
      "- A comprehensive list of academic papers, articles, and other sources that informed the research proposal, focusing on recent advancements in Gen AI, information retrieval, and medical literature analysis.\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conduct Academic Literature Review",
   "id": "54e63deb266d5682"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:24:28.518355Z",
     "start_time": "2025-04-06T20:23:43.295131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "papers_dir = \"Papers\"\n",
    "paper_files = [f for f in os.listdir(papers_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "academic_summaries = \"\"\n",
    "for paper in paper_files:\n",
    "    paper_path = os.path.join(papers_dir, paper)\n",
    "    text = extract_text_from_pdf(paper_path)\n",
    "    words = text.split()\n",
    "    summary_text = \" \".join(words[:1000])\n",
    "    prompt_summary = (\n",
    "        f\"Summarize the contributions and insights of the following academic paper excerpt related to Gen AI and medical paper retrieval:\\n\\n{summary_text}\"\n",
    "    )\n",
    "    summary = llm.predict(prompt_summary)\n",
    "    academic_summaries += f\"Paper: {paper}\\nSummary:\\n{summary}\\n\\n\"\n",
    "academic_summaries += \"Additional Google Scholar Papers:\\n\" + additional_papers\n",
    "print(\"Academic Summaries:\\n\", academic_summaries)\n",
    "append_to_summary_file(f\"Academic Summaries:\\n{academic_summaries}\")"
   ],
   "id": "6a59b480fffbb3c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic Summaries:\n",
      " Paper: Systematic Review LLM Apps.pdf\n",
      "Summary:\n",
      "The paper titled \"A Systematic Review of Testing and Evaluation of Healthcare Applications of Large Language Models (LLMs)\" by Suhana Bedi et al. provides a comprehensive analysis of how LLMs are currently evaluated in healthcare settings. The key findings highlight that real patient care data is rarely used in LLM evaluations, with only 5% of studies utilizing such data. The predominant focus has been on assessing medical knowledge, such as answering medical licensing exam questions, while administrative tasks like billing code assignment and prescription writing are understudied. Most evaluations prioritize accuracy, with limited attention to fairness, bias, toxicity, robustness, and deployment considerations. The study also notes a lack of evaluations in specialized medical fields like nuclear medicine and medical genetics.\n",
      "\n",
      "The paper emphasizes the need for more comprehensive and standardized evaluations of LLMs in healthcare, using real-world data and covering a broader range of tasks and specialties. This would help in drawing meaningful insights and improving the adoption of LLMs in healthcare. The authors argue that current evaluations are fragmented and shallow, lacking the necessary depth to guide effective deployment in real-world settings. They call for future studies to establish standardized evaluation dimensions and broaden testing to include various healthcare tasks and specialties. The paper underscores the potential of LLMs to significantly improve healthcare efficiency and outcomes, but stresses that their performance in real-world settings remains inconsistently evaluated.\n",
      "\n",
      "Paper: Transformative impact of LLM in Medicine.pdf\n",
      "Summary:\n",
      "The academic paper excerpt discusses the transformative impact of large language models (LLMs) in the field of medicine, highlighting their potential to revolutionize healthcare. LLMs, such as GPT-4 and BERT, have advanced significantly due to improvements in computing power and data availability, enabling them to excel in natural language processing (NLP) tasks. These models are capable of processing multimodal data, which enhances their application in emergency care, elder care, and digital medical procedures.\n",
      "\n",
      "The paper emphasizes the role of LLMs in clinical decision support, where they assist healthcare professionals in diagnosing diseases with greater accuracy and speed, provide treatment recommendations, and facilitate the analysis of medical records. LLMs are also instrumental in navigating vast medical literature, offering essential research and guidelines to healthcare professionals, thus saving time and ensuring treatments are based on current knowledge.\n",
      "\n",
      "Furthermore, LLMs can interact directly with patients, offering medical consultations and efficiently handling document processing. They are also emerging as valuable tools in drug research and development, aiding in new drug discoveries through detailed analysis of chemical and biological data.\n",
      "\n",
      "Despite their potential, the paper acknowledges challenges such as ensuring empirical reliability, addressing ethical and societal implications, particularly data privacy, and mitigating biases while maintaining privacy and accountability. The authors advocate for the development of human-centric, bias-free LLMs to support personalized medicine and emphasize the need for equitable development and access to these technologies.\n",
      "\n",
      "Overall, the paper underscores the promise of LLMs in transforming healthcare by equipping doctors with advanced tools for more accurate and efficient medical practice, while also highlighting the importance of addressing the associated challenges to fully realize their potential.\n",
      "\n",
      "Paper: yang-et-al-2024-application-of-large-language-models-in-disease-diagnosis-and-treatment.pdf\n",
      "Summary:\n",
      "The academic paper discusses the transformative role of large language models (LLMs) like ChatGPT, Claude, Llama, and Qwen in the medical field, particularly in disease diagnosis and treatment. These models excel in processing vast amounts of medical data and literature, enhancing diagnostic accuracy, and identifying rare diseases by recognizing subtle patterns in symptoms and test results. Multimodal LLMs (MLLMs) extend these capabilities to image-based diagnostics, such as radiography and CT scans, and assist in treatment planning by suggesting evidence-based interventions.\n",
      "\n",
      "Despite their potential, the paper highlights challenges such as algorithmic bias, hallucinations, and the need for rigorous clinical validation. Ethical considerations are crucial, emphasizing the importance of supervision in clinical practice. The paper underscores the rapid advancements in LLM research across medical disciplines and the need for policymaking, ethical oversight, and multidisciplinary collaboration to ensure effective and safe clinical applications.\n",
      "\n",
      "Future directions include integrating proprietary clinical knowledge, exploring open-source and customized models, and evaluating real-time effects in clinical settings. The paper also notes the importance of optimization techniques like prompt engineering and multi-agent systems to enhance LLM performance in professional tasks. Overall, the paper provides a comprehensive overview of the progress and challenges in using LLMs for medical diagnosis and treatment, advocating for continued research and collaboration to address existing limitations.\n",
      "\n",
      "Paper: Multimodal in healthcare.pdf\n",
      "Summary:\n",
      "The academic paper by Rawan AlSaad and colleagues explores the potential of multimodal large language models (M-LLMs) in the healthcare sector. The authors highlight the limitations of current large language models (LLMs), which primarily focus on processing text-based data, and emphasize the need for integrating diverse data modalities prevalent in medical practice. These modalities include medical images, time-series data, audio recordings, videos, and omics data, all of which are crucial for comprehensive clinical decision-making.\n",
      "\n",
      "The paper provides a detailed examination of the foundational principles of M-LLMs, their current and potential applications in healthcare, and the technical and ethical challenges they present. The authors propose a unified framework that connects these elements, aiming to guide future research and practical implementations of M-LLMs in healthcare. They argue that M-LLMs represent a paradigm shift towards integrated, data-driven medical practice, which could significantly enhance diagnosis, treatment planning, research, and patient care.\n",
      "\n",
      "The paper also discusses the evolution of LLMs, noting the transformative impact of deep learning and the introduction of transformer models, which have improved the ability to process sequential data and capture long-range dependencies. The authors anticipate that their work will inspire further discussion and innovation in the development of next-generation medical M-LLM systems, ultimately contributing to more effective and holistic healthcare solutions.\n",
      "\n",
      "Paper: Agents in Clinic.pdf\n",
      "Summary:\n",
      "The academic paper excerpt discusses the potential and challenges of using large language models (LLMs) as intelligent agents in clinical settings. The authors highlight the transformative capabilities of LLMs, such as GPT-4 and Med-PaLM 2, which extend beyond traditional natural language processing tasks to more complex, multi-step reasoning and decision-making processes in healthcare. These models can autonomously interact with clinical data, guidelines, and tools, offering support in both administrative and clinical decision-making tasks.\n",
      "\n",
      "The paper introduces the concept of \"Artificial Intelligence Structured Clinical Examinations\" (AI-SCE) as a framework for evaluating LLMs in real-world clinical environments, akin to the evaluation of autonomous vehicles. This involves using agent-based modeling (ABM) to simulate clinical settings, allowing for the assessment of LLM agents' interactions, decision-making processes, and potential points of failure.\n",
      "\n",
      "The authors emphasize the importance of developing robust evaluation frameworks to ensure the safe and effective deployment of LLM agents in healthcare. They also note the ongoing integration of LLMs in healthcare systems, such as UC San Diego Health's use of GPT-4 for patient messaging, and the exploration of virtual-first approaches for patient triaging. Overall, the paper underscores the need for comprehensive evaluation and development strategies to harness the full potential of LLMs in clinical applications.\n",
      "\n",
      "Paper: Autonomous Agents 2024 in medicine.pdf\n",
      "Summary:\n",
      "The academic paper explores the application of Generative Large Language Models (LLMs) as autonomous agents in healthcare, specifically for administering evidence-based clinical workflows. The study investigates the potential of LLMs to enhance decision-making in clinical settings by simulating their use in a tertiary care medical center. The research involves structuring real-world clinical cases into JSON files and presenting them to LLM-based agents, which utilize natural language prompts, real-world interaction tools, and standard programming techniques to solve these cases.\n",
      "\n",
      "Key contributions and insights from the paper include:\n",
      "\n",
      "1. **Functionality of LLMs in Healthcare**: The study demonstrates that LLMs, particularly when combined with Retrieval Augmented Generation (RAG), can function effectively as autonomous agents in healthcare. This approach helps in providing updated context and improving guideline adherence and response relevance.\n",
      "\n",
      "2. **Performance Evaluation**: The research evaluates the performance of both proprietary (e.g., GPT-4) and open-source LLMs across various medical specialties. Proprietary models generally outperform open-source ones, indicating the potential for LLMs to enhance clinical decision-making.\n",
      "\n",
      "3. **Challenges and Limitations**: The paper highlights several challenges associated with LLMs, such as data staleness, resource intensity, and the risk of generating incorrect or fabricated responses (hallucinations). These issues limit their applicability in dynamic healthcare environments.\n",
      "\n",
      "4. **Potential and Future Directions**: Despite the challenges, LLMs show promise in healthcare applications, particularly when integrated with real-world data and tailored prompts. The study suggests that further refinements in LLM technology and operational protocols are necessary to optimize their utility in healthcare settings.\n",
      "\n",
      "Overall, the paper underscores the potential of LLMs to transform healthcare by acting as autonomous agents that support evidence-based clinical workflows, while also acknowledging the need for ongoing improvements to address current limitations.\n",
      "\n",
      "Paper: Polaris LLM Constellation.pdf\n",
      "Summary:\n",
      "The paper \"Polaris: A Safety-focused LLM Constellation Architecture for Healthcare\" introduces Polaris2, a novel large language model (LLM) system designed for real-time patient-AI interactions in healthcare settings. Unlike previous LLM applications in healthcare that primarily focus on question-answering tasks, Polaris2 emphasizes long, multi-turn voice conversations. The system is a constellation of multiple LLMs, each with billions of parameters, working as cooperative agents. The primary agent is responsible for maintaining engaging and patient-friendly conversations, while specialist support agents handle specific healthcare tasks typically performed by nurses, social workers, and nutritionists. This architecture aims to enhance safety and minimize hallucinations in AI responses.\n",
      "\n",
      "The authors developed a sophisticated training protocol for iterative co-training of these agents, optimizing them for diverse objectives. The models were trained on proprietary data, clinical care plans, healthcare regulatory documents, medical manuals, and other medical reasoning documents. Additionally, the models were aligned to communicate like medical professionals through both organic and simulated healthcare conversations, enabling the system to exhibit capabilities such as rapport building, trust building, empathy, and advanced medical reasoning.\n",
      "\n",
      "A significant contribution of the paper is the comprehensive clinician evaluation of the LLM system, involving over 1100 U.S. licensed nurses and 130 U.S. licensed physicians. These professionals evaluated the system by posing as patients and rating it on various measures, including medical safety, clinical readiness, patient education, conversational quality, and bedside manner. The results showed that Polaris performs comparably to human nurses across these dimensions. Furthermore, the specialist support agents were evaluated on challenging tasks, demonstrating superior performance compared to larger general-purpose LLMs like GPT-4 and medium-sized models like LLaMA-2 70B.\n",
      "\n",
      "Overall, the paper highlights Polaris2's innovative approach to integrating safety-focused AI in healthcare, emphasizing its potential to enhance patient-AI interactions through specialized, cooperative LLM agents.\n",
      "\n",
      "Paper: LLM Agents in Medicine.pdf\n",
      "Summary:\n",
      "The academic paper titled \"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine\" by Hanguang Xiao and colleagues provides an extensive overview of the role and development of large language models (LLMs) and multimodal large language models (MLLMs) in the medical field. The paper highlights the transformative impact of models like ChatGPT and GPT-4, which have introduced new paradigms for integrating artificial intelligence into medicine through their capabilities in understanding, reasoning, and generation.\n",
      "\n",
      "Key contributions and insights from the paper include:\n",
      "\n",
      "1. **Paradigm Shift**: The paper traces the evolution from traditional models to LLMs and MLLMs, emphasizing their unique advantages in medical applications. It highlights the shift facilitated by the introduction of the Transformer model, which has revolutionized natural language processing and computer vision.\n",
      "\n",
      "2. **Comprehensive Review**: The survey provides a detailed review of existing medical LLMs and MLLMs, offering guidance on their construction and evaluation. It discusses notable models such as the PaLM, GPT, and LLaMA series among LLMs, and Gemini, GPT-4, and LLaVA among MLLMs.\n",
      "\n",
      "3. **Applications in Medicine**: The paper explores five promising applications of LLMs and MLLMs in healthcare, including medical report generation, clinical diagnosis, and mental health services. It underscores the potential of these models to enhance clinical decision support, disease diagnosis, and treatment planning.\n",
      "\n",
      "4. **Challenges and Solutions**: The survey addresses significant challenges in deploying medical LLMs and MLLMs, such as the need for substantial medical data, computational resources, and concerns about data privacy. It also discusses issues like hallucinations and the lack of up-to-date information, proposing practical strategies and future directions for overcoming these obstacles.\n",
      "\n",
      "5. **Technical Methodologies**: The paper delves into the technical aspects of LLMs and MLLMs, including datasets, model architectures, and construction methods. It provides a systematic elucidation of the training and evaluation process, covering fine-tuning methods and evaluation strategies.\n",
      "\n",
      "6. **Future Directions**: The survey offers forward-looking perspectives on the development of medical LLMs and MLLMs, aiming to inspire advancements in the field and promote deeper integration between artificial intelligence and healthcare.\n",
      "\n",
      "Overall, the paper serves as a comprehensive resource for understanding the current state and future potential of LLMs and MLLMs in medicine, providing valuable insights for researchers and medical professionals interested in leveraging these technologies to advance healthcare.\n",
      "\n",
      "Paper: MedAide.pdf\n",
      "Summary:\n",
      "The paper \"MEDAIDE: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration\" introduces a novel framework called MEDAIDE, designed to enhance the capabilities of Large Language Models (LLMs) in the healthcare domain. The authors address the limitations of current LLMs, such as their lack of personalized recommendations and diagnostic analysis, which can lead to hallucinations and performance bottlenecks in complex medical applications.\n",
      "\n",
      "Key contributions and insights from the paper include:\n",
      "\n",
      "1. **Omni Multi-Agent Collaboration Framework**: MEDAIDE is the first framework to propose an omni multi-agent collaboration approach for handling composite healthcare intents in real-world scenarios. This framework aims to advance interactive systems for personalized healthcare by effectively managing complex dialog goals through specialized paramedical agents.\n",
      "\n",
      "2. **Query Rewriting and Contextual Encoding**: The framework enhances the understanding of composite medical queries by performing query rewriting through retrieval-augmented generation. It also introduces a contextual encoder to learn intent prototype embeddings, which helps in recognizing fine-grained intents via similarity matching.\n",
      "\n",
      "3. **Specialized Agent Collaboration**: Different paramedical agents are activated based on the recognized intents to provide personalized and specialized medical expertise. This collaboration improves the strategic reasoning of LLMs and enhances their ability to fulfill dialog goals accurately.\n",
      "\n",
      "4. **Decision Analysis Module**: MEDAIDE includes a decision analysis module with Chain-of-Thought (CoT) properties, which summarizes the responses of activated agents to make integrated and faithful decisions.\n",
      "\n",
      "5. **Experimental Validation**: Extensive experiments conducted on seven medical benchmarks with 17 types of rich intents demonstrate the effectiveness of MEDAIDE. The framework shows competitive improvements over current LLMs in terms of medical proficiency and strategic reasoning.\n",
      "\n",
      "6. **Plug-and-Play Framework**: MEDAIDE can be readily combined with existing LLMs, providing a flexible and scalable solution for enhancing medical applications.\n",
      "\n",
      "Overall, the paper highlights the potential of MEDAIDE to improve the performance of LLMs in healthcare by addressing their current limitations and leveraging multi-agent collaboration for more accurate and personalized medical assistance.\n",
      "\n",
      "Paper: Adaptive Reasoning Language Agents.pdf\n",
      "Summary:\n",
      "The paper \"Adaptive Reasoning and Acting in Medical Language Agents\" by Abhishek Dutta and Yen-Che Hsiao introduces a novel framework for enhancing diagnostic accuracy in simulated clinical environments using large language models (LLMs). The framework is evaluated using the AgentClinic benchmark, which simulates real-world clinical settings through interactions between various agents, including a Doctor Agent, Patient Agent, Measurement Agent, and Moderator Agent.\n",
      "\n",
      "Key contributions and insights from the paper include:\n",
      "\n",
      "1. **Adaptive Framework for Doctor Agents**: The authors propose an automatic correction mechanism that allows doctor agents to iteratively refine their reasoning and actions after incorrect diagnoses. This adaptive feedback loop helps the agents learn from mistakes and improve their decision-making over time.\n",
      "\n",
      "2. **Evaluation in Simulated Environments**: The framework is tested in the AgentClinic environment, which mimics the complexities of clinical settings through dynamic doctor-patient dialogues and medical test interpretations. The evaluations demonstrate that the adaptive LLM-based doctor agents can achieve correct diagnoses through iterative interactions with simulated patients.\n",
      "\n",
      "3. **Handling Diagnostic Failures**: A significant focus of the work is on managing cases where the doctor agent initially fails to provide an accurate diagnosis. The proposed system guides the agent through adaptive reasoning to correct earlier mistakes and reach a proper diagnosis.\n",
      "\n",
      "4. **Potential of Autonomous Agents in Healthcare**: The study highlights the potential of autonomous agents to enhance diagnostic processes in healthcare by enabling iterative refinement of reasoning, ultimately leading to improved diagnostic accuracy.\n",
      "\n",
      "5. **Future Directions**: The authors suggest future enhancements to refine the algorithm and expand its applicability across a broader range of tasks and different LLMs.\n",
      "\n",
      "Overall, the paper underscores the potential of LLMs in healthcare, particularly in dynamic and interactive clinical environments, and provides a framework for improving diagnostic accuracy through adaptive learning and reasoning.\n",
      "\n",
      "Additional Google Scholar Papers:\n",
      "Title: \n",
      "Snippet: RAG enhances LLM's capabilities by giving access to different information sources in real-time and seamlessly integrating them with processing.\n",
      "\n",
      "Title: Developing Retrieval Augmented Generation (RAG) based LLM ...\n",
      "Snippet: This paper presents an experience report on the development of Retrieval Augmented Generation (RAG) systems using PDF documents as the primary data source.\n",
      "\n",
      "Title: Retrieval-augmented generation for generative artificial intelligence ...\n",
      "Snippet: Retrieval-augmented generation (RAG) enables models to generate more reliable content by leveraging the retrieval of external knowledge.\n",
      "\n",
      "Title: Evaluating Medical Retrieval-Augmented Generation (RAG) with ...\n",
      "Snippet: In this overview, we'll explore RAG's growing role in healthcare, focusing on its potential to transform applications like drug discovery and clinical trials.\n",
      "\n",
      "Title: What is retrieval-augmented generation? - Red Hat\n",
      "Snippet: Retrieval-augmented generation (RAG) links external resources to an LLM to enhance a generative AI model's output accuracy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate The Final Proposal",
   "id": "4d25acf9357797d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:24:28.543098Z",
     "start_time": "2025-04-06T20:24:28.540161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_section(section_name, context):\n",
    "    initial_prompt = (\n",
    "        f\"Write the {section_name} for a research proposal on the topic:\\n'{research_topic}'.\\nContext:\\n{context}\\n\"\n",
    "    )\n",
    "    draft = llm.predict(initial_prompt)\n",
    "    revised = iterative_revision(draft, section_name)\n",
    "    append_to_summary_file(f\"{section_name} Final Text:\\n{revised}\")\n",
    "    return revised"
   ],
   "id": "15c60253eca3d372",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:24:28.557841Z",
     "start_time": "2025-04-06T20:24:28.554719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_context = \"Generate a concise, catchy title that reflects using a RAG LLM for retrieval of medical papers.\"\n",
    "abstract_context = (\n",
    "    \"Summarize the proposal in 150–250 words, including the motivation, methodology (centralized vector store and RAG LLM retrieval), \"\n",
    "    \"and expected impact on academic research in healthcare.\"\n",
    ")\n",
    "bkg_context = (\n",
    "    \"Provide a comprehensive background and literature review on current methods in medical paper retrieval, \"\n",
    "    \"their limitations, and how a RAG LLM could improve the process. Include insights from the academic summaries.\"\n",
    ")\n",
    "problem_context = (\n",
    "    \"Describe the problem and research gaps identified, focusing on limitations of current retrieval systems and challenges \"\n",
    "    \"in building a centralized vector store for academic literature.\"\n",
    ")\n",
    "approach_context = (\n",
    "    \"Detail the proposed Gen AI approach, including the architecture of the RAG LLM, integration with a vector store, \"\n",
    "    \"data processing, and experimental design.\"\n",
    ")\n",
    "impact_context = (\n",
    "    \"Discuss the expected impact on healthcare research, including improvements in literature retrieval efficiency, research speed, \"\n",
    "    \"and data accessibility.\"\n",
    ")\n",
    "limits_context = (\n",
    "    \"Identify potential limitations and ethical considerations such as data privacy, biases, and scaling challenges.\"\n",
    ")\n",
    "references_context = (\n",
    "    \"List key academic references supporting the proposal, including the papers summarized and additional relevant citations.\"\n",
    ")"
   ],
   "id": "f7cd45767db59b95",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:28:47.315276Z",
     "start_time": "2025-04-06T20:24:28.560960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proposal_sections = {}\n",
    "proposal_sections[\"Title\"] = generate_section(\"Title\", title_context)\n",
    "proposal_sections[\"Abstract\"] = generate_section(\"Abstract\", abstract_context)\n",
    "# Escape ampersands in section titles for LaTeX formatting.\n",
    "proposal_sections[\"Background \\\\& Literature Review\"] = generate_section(\"Background & Literature Review\", bkg_context)\n",
    "proposal_sections[\"Problem Statement \\\\& Research Gap\"] = generate_section(\"Problem Statement & Research Gap\", problem_context)\n",
    "proposal_sections[\"Proposed Gen AI Approach\"] = generate_section(\"Proposed Gen AI Approach\", approach_context)\n",
    "proposal_sections[\"Expected Impact in Healthcare\"] = generate_section(\"Expected Impact in Healthcare\", impact_context)\n",
    "proposal_sections[\"Limitations or Ethical Considerations\"] = generate_section(\"Limitations or Ethical Considerations\", limits_context)\n",
    "proposal_sections[\"References\"] = generate_section(\"References\", references_context)"
   ],
   "id": "1bf86a34a6acee12",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate LaTeX File",
   "id": "edb367e342a09dd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:30:25.504423Z",
     "start_time": "2025-04-06T20:28:47.339410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latex_sections = {}\n",
    "for sec, content in proposal_sections.items():\n",
    "    latex_code = generate_section_latex(sec, content)\n",
    "    latex_sections[sec] = latex_code\n",
    "\n",
    "# Assemble final LaTeX document.\n",
    "final_latex_document = r\"\"\"\\documentclass[12pt]{article}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage{lmodern}\n",
    "\\usepackage{hyperref}\n",
    "\\usepackage{geometry}\n",
    "\\geometry{margin=1in}\n",
    "\\title{%s}\n",
    "\\author{Generated by Unified Research Proposal Agent}\n",
    "\\date{\\today}\n",
    "\\begin{document}\n",
    "\\maketitle\n",
    "\"\"\" % (escape_latex(proposal_sections[\"Title\"]).strip())"
   ],
   "id": "565b42f698d68bcb",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:30:25.528873Z",
     "start_time": "2025-04-06T20:30:25.522032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section_order = [\n",
    "    \"Abstract\", \"Background \\\\& Literature Review\", \"Problem Statement \\\\& Research Gap\",\n",
    "    \"Proposed Gen AI Approach\", \"Expected Impact in Healthcare\",\n",
    "    \"Limitations or Ethical Considerations\", \"References\"\n",
    "]\n",
    "\n",
    "for sec in section_order:\n",
    "    final_latex_document += \"\\n\\\\section*{%s}\\n%s\\n\" % (sec, latex_sections[sec])\n",
    "\n",
    "final_latex_document += \"\\n\\\\end{document}\"\n",
    "\n",
    "latex_file = \"Assignment 2/final_proposal.tex\"\n",
    "os.makedirs(os.path.dirname(latex_file), exist_ok=True)\n",
    "with open(latex_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_latex_document)\n",
    "print(f\"Final LaTeX proposal written to {latex_file}\")"
   ],
   "id": "ddb4ad7eec1415b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LaTeX proposal written to Assignment 2/final_proposal.tex\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:40:01.454954Z",
     "start_time": "2025-04-06T20:40:01.168811Z"
    }
   },
   "cell_type": "code",
   "source": "subprocess.run([\"pdflatex\", \"-output-directory\", os.path.dirname(latex_file), latex_file])",
   "id": "a30b56e1da554da8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) (preloaded format=pdflatex)\n",
      " \\write18 enabled.\n",
      "entering extended mode\n",
      "(./Assignment 2/final_proposal.tex\n",
      "LaTeX2e <2024-11-01>\n",
      "L3 programming layer <2024-11-02>\n",
      "(/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2024/06/29 v1.4n Standard LaTeX document class\n",
      "(/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/base/size12.clo)) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/base/inputenc.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/lm/lmodern.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/hyperref/hyperref.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/iftex/iftex.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/graphics/keyval.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/pdfescape/pdfescape.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/infwarerr/infwarerr.sty))) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/hycolor/hycolor.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/hyperref/nameref.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/refcount/refcount.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/kvoptions/kvoptions.sty))) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/etoolbox/etoolbox.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/stringenc/stringenc.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/hyperref/pd1enc.def) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/intcalc/intcalc.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/hyperref/puenc.def) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/url/url.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/bitset/bitset.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty)) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/base/atbegshi-ltx.sty)) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/hyperref/hpdftex.def (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/base/atveryend-ltx.sty) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty))) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/geometry/geometry.sty (/Users/kyler/Library/TinyTeX/texmf-dist/tex/generic/iftex/ifvtex.sty)) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/lm/ot1lmr.fd) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/l3backend/l3backend-pdftex.def) (Assignment 2/final_proposal.aux) (Assignment 2/final_proposal.out) (Assignment 2/final_proposal.out)\n",
      "*geometry* driver: auto-detecting\n",
      "*geometry* detected driver: pdftex\n",
      "(/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/lm/omllmm.fd) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/lm/omslmsy.fd) (/Users/kyler/Library/TinyTeX/texmf-dist/tex/latex/lm/omxlmex.fd)\n",
      "! Misplaced alignment tab character &.\n",
      "l.17 **Background &\n",
      "                    Literature Review**\n",
      "? \n",
      "! Emergency stop.\n",
      "l.17 \n",
      "     \n",
      "!  ==> Fatal error occurred, no output PDF file produced!\n",
      "Transcript written on \"Assignment 2/final_proposal.log\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pdflatex', '-output-directory', 'Assignment 2', 'Assignment 2/final_proposal.tex'], returncode=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate Beamer Slide Deck",
   "id": "9d6c8276189c4a31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:30:25.947927Z",
     "start_time": "2025-04-06T20:30:25.944979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "beamer_prompt = (\n",
    "    \"Generate a complete Beamer slide deck in LaTeX (maximum 10 slides) for the following research proposal. \"\n",
    "    \"The slides should include a title slide, an overview of the proposal sections, and individual slides for each major section \"\n",
    "    \"(Abstract, Background & Literature Review, Problem Statement & Research Gap, Proposed Gen AI Approach, Expected Impact in Healthcare, \"\n",
    "    \"Limitations or Ethical Considerations, References) as well as a slide describing the system workflow and user interaction (with a diagram description) \"\n",
    "    \"and a conclusion/future work slide. Use advanced LaTeX formatting options such as enumerate, itemize, bold, etc. Output only the LaTeX code.\\n\\n\"\n",
    "    \"Proposal Sections:\\n\"\n",
    ")\n",
    "for sec, content in proposal_sections.items():\n",
    "    beamer_prompt += f\"\\\\textbf{{{sec}}}: {content}\\n\\n\""
   ],
   "id": "5ce0317edc3e5d76",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:30:34.699886Z",
     "start_time": "2025-04-06T20:30:25.961488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_slide_deck = llm.predict(beamer_prompt)\n",
    "print(\"Initial Slide Deck LaTeX:\\n\", initial_slide_deck)\n",
    "append_to_summary_file(\"Initial Slide Deck LaTeX:\\n\" + initial_slide_deck)"
   ],
   "id": "ebebe6523dd156a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Slide Deck LaTeX:\n",
      " ```latex\n",
      "\\documentclass{beamer}\n",
      "\\usepackage{graphicx}\n",
      "\\usepackage{amsmath}\n",
      "\n",
      "\\title{MedRAG: Transforming Medical Research Retrieval through AI-Enhanced Vector Stores}\n",
      "\\author{Research Proposal}\n",
      "\\date{\\today}\n",
      "\n",
      "\\begin{document}\n",
      "\n",
      "\\begin{frame}\n",
      "  \\titlepage\n",
      "\\end{frame}\n",
      "\n",
      "\\begin{frame}{Overview}\n",
      "  \\tableofcontents\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Abstract}\n",
      "\\begin{frame}{Abstract}\n",
      "  \\textbf{Objective:} Develop a Retrieval-Augmented Generation (RAG) LLM for efficient retrieval of medical literature.\\\\\n",
      "  \\textbf{Motivation:} Address inefficiencies in accessing medical research.\\\\\n",
      "  \\textbf{Methodology:} Integrate RAG LLM with a centralized vector store.\\\\\n",
      "  \\textbf{Impact:} Transform academic research in healthcare by streamlining access to critical information.\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Background \\& Literature Review}\n",
      "\\begin{frame}{Background \\& Literature Review}\n",
      "  \\textbf{Background:}\n",
      "  \\begin{itemize}\n",
      "    \\item Traditional retrieval systems rely on keyword-based search engines.\n",
      "    \\item Limitations in precision, recall, and contextual understanding.\n",
      "  \\end{itemize}\n",
      "  \\textbf{Literature Review:}\n",
      "  \\begin{enumerate}\n",
      "    \\item Current Methods in Medical Paper Retrieval\n",
      "    \\item Limitations of Current Methods\n",
      "    \\item Emergence of RAG Models\n",
      "    \\item Potential Impact of RAG LLMs\n",
      "  \\end{enumerate}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Problem Statement \\& Research Gap}\n",
      "\\begin{frame}{Problem Statement \\& Research Gap}\n",
      "  \\textbf{Problem Statement:}\n",
      "  \\begin{itemize}\n",
      "    \\item Challenges in accessing pertinent medical literature.\n",
      "    \\item Limitations of traditional retrieval systems.\n",
      "  \\end{itemize}\n",
      "  \\textbf{Research Gap:}\n",
      "  \\begin{enumerate}\n",
      "    \\item Limitations of Current Retrieval Systems\n",
      "    \\item Challenges in Building a Centralized Vector Store\n",
      "  \\end{enumerate}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Proposed Gen AI Approach}\n",
      "\\begin{frame}{Proposed Gen AI Approach}\n",
      "  \\textbf{Architecture of the RAG LLM:}\n",
      "  \\begin{itemize}\n",
      "    \\item \\textbf{Retriever Component:} Dense passage retrieval approach.\n",
      "    \\item \\textbf{Generator Component:} Transformer-based LLM.\n",
      "    \\item \\textbf{Integration:} Pipeline of retriever and generator.\n",
      "  \\end{itemize}\n",
      "  \\textbf{Integration with a Vector Store:}\n",
      "  \\begin{itemize}\n",
      "    \\item Centralized vector store using scalable databases.\n",
      "    \\item Data ingestion and indexing for efficient retrieval.\n",
      "  \\end{itemize}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{System Workflow and User Interaction}\n",
      "\\begin{frame}{System Workflow and User Interaction}\n",
      "  \\textbf{Workflow:}\n",
      "  \\begin{enumerate}\n",
      "    \\item User submits a query.\n",
      "    \\item Query is embedded into vector space.\n",
      "    \\item Retriever performs nearest-neighbor search.\n",
      "    \\item Generator produces contextually relevant response.\n",
      "  \\end{enumerate}\n",
      "  \\textbf{Diagram:}\n",
      "  \\begin{center}\n",
      "    \\includegraphics[width=0.8\\textwidth]{workflow_diagram.png}\n",
      "  \\end{center}\n",
      "  \\textit{Note: Diagram illustrates the interaction between user queries, vector store, retriever, and generator.}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Expected Impact in Healthcare}\n",
      "\\begin{frame}{Expected Impact in Healthcare}\n",
      "  \\begin{itemize}\n",
      "    \\item Enhanced Literature Retrieval Efficiency\n",
      "    \\item Accelerated Research Pace\n",
      "    \\item Improved Data Accessibility\n",
      "    \\item Promotion of Interdisciplinary Research\n",
      "    \\item Support for Evidence-Based Practice\n",
      "    \\item Mitigation of Information Overload\n",
      "  \\end{itemize}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Limitations or Ethical Considerations}\n",
      "\\begin{frame}{Limitations or Ethical Considerations}\n",
      "  \\textbf{Limitations:}\n",
      "  \\begin{itemize}\n",
      "    \\item Data Quality and Availability\n",
      "    \\item Scalability\n",
      "    \\item Technical Challenges\n",
      "  \\end{itemize}\n",
      "  \\textbf{Ethical Considerations:}\n",
      "  \\begin{itemize}\n",
      "    \\item Data Privacy\n",
      "    \\item Bias and Fairness\n",
      "    \\item Ethical Use of Information\n",
      "    \\item Impact on Research and Practice\n",
      "  \\end{itemize}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{References}\n",
      "\\begin{frame}{References}\n",
      "  \\begin{enumerate}\n",
      "    \\item Lewis, P., et al. (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.\"\n",
      "    \\item Karpukhin, V., et al. (2020). \"Dense Passage Retrieval for Open-Domain Question Answering.\"\n",
      "    \\item Johnson, J., et al. (2019). \"Billion-scale similarity search with GPUs.\"\n",
      "    \\item Devlin, J., et al. (2019). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\"\n",
      "    \\item Vaswani, A., et al. (2017). \"Attention is All You Need.\"\n",
      "  \\end{enumerate}\n",
      "\\end{frame}\n",
      "\n",
      "\\section{Conclusion \\& Future Work}\n",
      "\\begin{frame}{Conclusion \\& Future Work}\n",
      "  \\textbf{Conclusion:}\n",
      "  \\begin{itemize}\n",
      "    \\item RAG LLM can revolutionize medical literature retrieval.\n",
      "    \\item Enhances efficiency, speed, and accessibility.\n",
      "  \\end{itemize}\n",
      "  \\textbf{Future Work:}\n",
      "  \\begin{itemize}\n",
      "    \\item Further fine-tuning of the model for specific medical subdomains.\n",
      "    \\item Exploration of additional ethical frameworks.\n",
      "    \\item Expansion of the vector store to include more diverse datasets.\n",
      "  \\end{itemize}\n",
      "\\end{frame}\n",
      "\n",
      "\\end{document}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:31:16.859927Z",
     "start_time": "2025-04-06T20:30:34.716582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "slide_deck_revised = iterative_revision(initial_slide_deck, \"Slide Deck\")\n",
    "beamer_file = \"Assignment 2/slide_deck.tex\"\n",
    "with open(beamer_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(slide_deck_revised)\n",
    "print(f\"Slide deck LaTeX written to {beamer_file}\")"
   ],
   "id": "552c64401656dcfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide deck LaTeX written to Assignment 2/slide_deck.tex\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:40:40.237378Z",
     "start_time": "2025-04-06T20:40:40.180039Z"
    }
   },
   "cell_type": "code",
   "source": "subprocess.run([\"pdflatex\", \"-output-directory\", os.path.dirname(beamer_file), beamer_file])",
   "id": "c8e5a11bd8a05f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) (preloaded format=pdflatex)\n",
      " \\write18 enabled.\n",
      "entering extended mode\n",
      "(./Assignment 2/slide_deck.tex\n",
      "LaTeX2e <2024-11-01>\n",
      "L3 programming layer <2024-11-02>\n",
      "\n",
      "! LaTeX Error: Missing \\begin{document}.\n",
      "\n",
      "See the LaTeX manual or LaTeX Companion for explanation.\n",
      "Type  H <return>  for immediate help.\n",
      " ...                                              \n",
      "                                                  \n",
      "l.1 `\n",
      "     ``latex\n",
      "? \n",
      "! Emergency stop.\n",
      " ...                                              \n",
      "                                                  \n",
      "l.1 `\n",
      "     ``latex\n",
      "!  ==> Fatal error occurred, no output PDF file produced!\n",
      "Transcript written on \"Assignment 2/slide_deck.log\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pdflatex', '-output-directory', 'Assignment 2', 'Assignment 2/slide_deck.tex'], returncode=1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:31:16.944380Z",
     "start_time": "2025-04-06T20:31:16.942739Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9bbdfff6cd4d5b5e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
