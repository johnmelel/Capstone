{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c1f2e6",
   "metadata": {},
   "source": [
    "# Corrections\n",
    "1. i am using pillow for image import, but my images are inside the PDFs...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb10ebe",
   "metadata": {},
   "source": [
    "# Medical Knowledge System with Multi-Agent Architecture\n",
    "\n",
    "This notebook implements a comprehensive medical knowledge system using:\n",
    "- **Multi-Agent Architecture**: Agent Manager, Planning Agent, Text/Image Retrievers, Reasoner, and Draft Agent\n",
    "- **A2A Communication**: Agent-to-Agent messaging system\n",
    "- **MCP Integration**: Model Context Protocol for agent communication\n",
    "- **Milvus Vector Store**: For storing and retrieving embeddings\n",
    "- **LangChain**: For agent orchestration and LLM integration\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "1. **Agent Manager**: Oversees all agents and coordinates communication\n",
    "2. **Planning Agent**: Analyzes queries to determine what information is needed\n",
    "3. **Text Retriever Agent**: Searches through textbooks and research papers\n",
    "4. **Image Retriever Agent**: Processes images from medical documents\n",
    "5. **Reasoner Agent**: Synthesizes information from all sources\n",
    "6. **Draft Agent**: Generates final responses for doctors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install langchain langchain-community langchain-openai pymilvus transformers torch torchvision pillow sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os                        # python model for interacting with operating system. we need it to access environment variables (like API keys)\n",
    "import logging                   # module to record events/errors (debugging and monitoritng)\n",
    "import json                      # to work with the structured data? (maybe)\n",
    "import asyncio                   # asynchronous programming (to potentially run multiple tasks concurrently. not heavily used here though)\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union  # to specify what type of data functions expect/return\n",
    "from dataclasses import dataclass  \n",
    "from abc import ABC, abstractmethod   \n",
    "import uuid                      # module to generate universally unique identifiers\n",
    "from datetime import datetime\n",
    "\n",
    "# Document processing\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader  # (PyPDFLoader: loads pdf and extracts them) (DirectoryLoader: load files matching a pattern from a directory. this is to upload all medical docs)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # text splitter (hyperparameter: chunk_size)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus  # integration with Milvus vector database\n",
    "\n",
    "# LLM and agents\n",
    "from langchain_openai import ChatOpenAI                                           # wrapper for openAI's GPT models (to use GPT-something for reasoning and response generation. requires openAI API costs)\n",
    "from langchain_core.prompts import ChatPromptTemplate                             # template for creating prompts (do we really need it?)\n",
    "from langchain_core.output_parsers import StrOutputParser                         # extracts string output from LLM responses. LLMs return complex objects, this just gets the text\n",
    "from langchain_core.runnables import RunnablePassthrough                          \n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool              # (AgentExecutor: runs agents & manages execution) (create_react_agent: creates ReAct agent) (tool: defines tools agents can use. we need this to create autonomous agents)\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage  # different types of messages in conversation. we need this to structure conversations with LLMs (HumanMessage: from user) (AIMessage: from the ai) (SystemMessage: instructions to the ai) (BaseMessage: parent class of all messages)\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image               # to load images before processing them\n",
    "import torch                        # pytorch\n",
    "from torchvision import transforms  # image transformation utilities (to preprocess images for neural networks)\n",
    "import clip                         # openAI's model that understands both images and text\n",
    "\n",
    "# Vector store\n",
    "from pymilvus import connections, Collection, utility   # (connections: Manages connections to milvus database) (Collection: represents collection—like a table—in milvus) (utility: helper functions, allows us to interact with milvus vector database)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,             # show INFO level and above (INFO, WARNING, ERROR, CRITICAL)\n",
    "format='%(asctime)s - %(levelname)s - %(message)s') # (\"%(asctime)s\": timestamp when log was created) (\"%(levelname)s\": level) (\"%(message)s\": actual log message) (Example output: 2025-10-02 14:30:15 - INFO - System initialized)\n",
    "logger = logging.getLogger(__name__)                # you can log how agent works along each module (each .py file is a module. for ex: agents.py, retrieval.py). you'll log uses so you see \"agent.planning_agent - INFO - Analyzing query\"\n",
    "\n",
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "TEXT_COLLECTION = \"medical_text\"    # names for milvus collections, like table names (built separate connections for image and text bc they have diff embedding dimensions)\n",
    "IMAGE_COLLECTION = \"medical_images\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f7adc",
   "metadata": {},
   "source": [
    "## Core Communication Protocols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class A2AMessage:\n",
    "    \"\"\"Agent-to-Agent message for communication between agents\"\"\"\n",
    "    message_id: str\n",
    "    sender: str\n",
    "    receiver: str\n",
    "    message_type: str\n",
    "    content: Dict[str, Any]\n",
    "    timestamp: datetime\n",
    "    priority: int = 1  # 1=normal, 2=high, 3=urgent\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.message_id:\n",
    "            self.message_id = str(uuid.uuid4())\n",
    "        if not self.timestamp:\n",
    "            self.timestamp = datetime.now()\n",
    "\n",
    "@dataclass\n",
    "class MCPRequest:\n",
    "    \"\"\"Model Context Protocol request\"\"\"\n",
    "    request_id: str\n",
    "    model: str\n",
    "    prompt: str\n",
    "    context: Dict[str, Any]\n",
    "    parameters: Dict[str, Any] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.request_id:\n",
    "            self.request_id = str(uuid.uuid4())\n",
    "        if not self.parameters:\n",
    "            self.parameters = {}\n",
    "\n",
    "@dataclass\n",
    "class MCPResponse:\n",
    "    \"\"\"Model Context Protocol response\"\"\"\n",
    "    request_id: str\n",
    "    result: Any\n",
    "    metadata: Dict[str, Any] = None\n",
    "    success: bool = True\n",
    "    error_message: str = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.metadata:\n",
    "            self.metadata = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039011d9",
   "metadata": {},
   "source": [
    "## Base Agent Class and Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent(ABC):\n",
    "    \"\"\"Base class for all agents in the system\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, agent_type: str):\n",
    "        self.name = name\n",
    "        self.agent_type = agent_type\n",
    "        self.mailbox: List[A2AMessage] = []\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "        self.logger = logging.getLogger(f\"agent.{name}\")\n",
    "        \n",
    "    def send_message(self, receiver: str, message_type: str, content: Dict[str, Any], \n",
    "                    priority: int = 1, manager=None):\n",
    "        \"\"\"Send a message to another agent\"\"\"\n",
    "        message = A2AMessage(\n",
    "            message_id=\"\",\n",
    "            sender=self.name,\n",
    "            receiver=receiver,\n",
    "            message_type=message_type,\n",
    "            content=content,\n",
    "            timestamp=datetime.now(),\n",
    "            priority=priority\n",
    "        )\n",
    "        if manager:\n",
    "            manager.deliver_message(message)\n",
    "        return message\n",
    "    \n",
    "    def receive_message(self, message: A2AMessage):\n",
    "        \"\"\"Receive a message from another agent\"\"\"\n",
    "        self.mailbox.append(message)\n",
    "        self.logger.info(f\"Received message from {message.sender}: {message.message_type}\")\n",
    "    \n",
    "    def process_messages(self):\n",
    "        \"\"\"Process all messages in the mailbox\"\"\"\n",
    "        while self.mailbox:\n",
    "            message = self.mailbox.pop(0)\n",
    "            self.handle_message(message)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        \"\"\"Handle a specific message - must be implemented by subclasses\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def make_mcp_request(self, model: str, prompt: str, context: Dict[str, Any], \n",
    "                        parameters: Dict[str, Any] = None) -> MCPRequest:\n",
    "        \"\"\"Create an MCP request\"\"\"\n",
    "        return MCPRequest(\n",
    "            request_id=\"\",\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            context=context,\n",
    "            parameters=parameters or {}\n",
    "        )\n",
    "\n",
    "class VectorStoreManager:\n",
    "    \"\"\"Manages Milvus vector store operations\"\"\"\n",
    "    \n",
    "    def __init__(self, host: str = MILVUS_HOST, port: str = MILVUS_PORT):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.connection_args = {\"host\": host, \"port\": port}\n",
    "        self.text_collection = None\n",
    "        self.image_collection = None\n",
    "        self.logger = logging.getLogger(\"vector_store\")\n",
    "        \n",
    "    def connect(self):\n",
    "        \"\"\"Connect to Milvus\"\"\"\n",
    "        try:\n",
    "            connections.connect(\"default\", host=self.host, port=self.port)\n",
    "            self.logger.info(f\"Connected to Milvus at {self.host}:{self.port}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to connect to Milvus: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def create_collections(self, text_embedding_dim: int = 384, image_embedding_dim: int = 512):\n",
    "        \"\"\"Create text and image collections\"\"\"\n",
    "        if not self.connect():\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            # Create text collection\n",
    "            text_schema = {\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"id\", \"type\": \"varchar\", \"is_primary\": True, \"max_length\": 100},\n",
    "                    {\"name\": \"embedding\", \"type\": \"float_vector\", \"dim\": text_embedding_dim},\n",
    "                    {\"name\": \"text\", \"type\": \"varchar\", \"max_length\": 10000},\n",
    "                    {\"name\": \"metadata\", \"type\": \"json\"}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            if not utility.has_collection(TEXT_COLLECTION):\n",
    "                from pymilvus import CollectionSchema, FieldSchema, DataType\n",
    "                \n",
    "                # Define fields\n",
    "                id_field = FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, max_length=100)\n",
    "                embedding_field = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=text_embedding_dim)\n",
    "                text_field = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=10000)\n",
    "                metadata_field = FieldSchema(name=\"metadata\", dtype=DataType.JSON)\n",
    "                \n",
    "                # Create schema\n",
    "                schema = CollectionSchema(\n",
    "                    fields=[id_field, embedding_field, text_field, metadata_field],\n",
    "                    description=\"Medical text collection\"\n",
    "                )\n",
    "                \n",
    "                # Create collection\n",
    "                self.text_collection = Collection(name=TEXT_COLLECTION, schema=schema)\n",
    "                self.logger.info(f\"Created text collection: {TEXT_COLLECTION}\")\n",
    "            else:\n",
    "                self.text_collection = Collection(TEXT_COLLECTION)\n",
    "                self.logger.info(f\"Connected to existing text collection: {TEXT_COLLECTION}\")\n",
    "            \n",
    "            # Create image collection (similar process)\n",
    "            if not utility.has_collection(IMAGE_COLLECTION):\n",
    "                from pymilvus import CollectionSchema, FieldSchema, DataType\n",
    "                \n",
    "                # Define fields for images\n",
    "                id_field = FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, max_length=100)\n",
    "                embedding_field = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=image_embedding_dim)\n",
    "                image_path_field = FieldSchema(name=\"image_path\", dtype=DataType.VARCHAR, max_length=500)\n",
    "                metadata_field = FieldSchema(name=\"metadata\", dtype=DataType.JSON)\n",
    "                \n",
    "                # Create schema\n",
    "                schema = CollectionSchema(\n",
    "                    fields=[id_field, embedding_field, image_path_field, metadata_field],\n",
    "                    description=\"Medical image collection\"\n",
    "                )\n",
    "                \n",
    "                # Create collection\n",
    "                self.image_collection = Collection(name=IMAGE_COLLECTION, schema=schema)\n",
    "                self.logger.info(f\"Created image collection: {IMAGE_COLLECTION}\")\n",
    "            else:\n",
    "                self.image_collection = Collection(IMAGE_COLLECTION)\n",
    "                self.logger.info(f\"Connected to existing image collection: {IMAGE_COLLECTION}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to create collections: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def insert_texts(self, texts: List[str], embeddings: List[List[float]], \n",
    "                    metadata: List[Dict[str, Any]]):\n",
    "        \"\"\"Insert text documents into the collection\"\"\"\n",
    "        if not self.text_collection:\n",
    "            self.logger.error(\"Text collection not initialized\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            ids = [str(uuid.uuid4()) for _ in texts]\n",
    "            data = [ids, embeddings, texts, metadata]\n",
    "            self.text_collection.insert(data)\n",
    "            self.text_collection.flush()\n",
    "            self.logger.info(f\"Inserted {len(texts)} text documents\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to insert texts: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def insert_images(self, image_paths: List[str], embeddings: List[List[float]], \n",
    "                     metadata: List[Dict[str, Any]]):\n",
    "        \"\"\"Insert image documents into the collection\"\"\"\n",
    "        if not self.image_collection:\n",
    "            self.logger.error(\"Image collection not initialized\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            ids = [str(uuid.uuid4()) for _ in image_paths]\n",
    "            data = [ids, embeddings, image_paths, metadata]\n",
    "            self.image_collection.insert(data)\n",
    "            self.image_collection.flush()\n",
    "            self.logger.info(f\"Inserted {len(image_paths)} image documents\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to insert images: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_texts(self, query_embedding: List[float], top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for similar text documents\"\"\"\n",
    "        if not self.text_collection:\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            self.text_collection.load()\n",
    "            results = self.text_collection.search(\n",
    "                data=[query_embedding],\n",
    "                anns_field=\"embedding\",\n",
    "                param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},\n",
    "                limit=top_k,\n",
    "                output_fields=[\"text\", \"metadata\"]\n",
    "            )\n",
    "            \n",
    "            hits = []\n",
    "            for hit in results[0]:\n",
    "                hits.append({\n",
    "                    \"id\": hit.id,\n",
    "                    \"score\": hit.distance,\n",
    "                    \"text\": hit.entity.get(\"text\"),\n",
    "                    \"metadata\": hit.entity.get(\"metadata\")\n",
    "                })\n",
    "            return hits\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to search texts: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def search_images(self, query_embedding: List[float], top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for similar image documents\"\"\"\n",
    "        if not self.image_collection:\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            self.image_collection.load()\n",
    "            results = self.image_collection.search(\n",
    "                data=[query_embedding],\n",
    "                anns_field=\"embedding\",\n",
    "                param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},\n",
    "                limit=top_k,\n",
    "                output_fields=[\"image_path\", \"metadata\"]\n",
    "            )\n",
    "            \n",
    "            hits = []\n",
    "            for hit in results[0]:\n",
    "                hits.append({\n",
    "                    \"id\": hit.id,\n",
    "                    \"score\": hit.distance,\n",
    "                    \"image_path\": hit.entity.get(\"image_path\"),\n",
    "                    \"metadata\": hit.entity.get(\"metadata\")\n",
    "                })\n",
    "            return hits\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to search images: {e}\")\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec39bc",
   "metadata": {},
   "source": [
    "## Embedding Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7402ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedder:\n",
    "    \"\"\"Handles text embedding using medical domain models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.embedder = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
    "        )\n",
    "        self.logger = logging.getLogger(\"text_embedder\")\n",
    "        \n",
    "    def embed_texts(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed a list of texts\"\"\"\n",
    "        try:\n",
    "            embeddings = self.embedder.embed_documents(texts)\n",
    "            self.logger.info(f\"Embedded {len(texts)} texts\")\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to embed texts: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def embed_query(self, query: str) -> List[float]:\n",
    "        \"\"\"Embed a single query\"\"\"\n",
    "        try:\n",
    "            embedding = self.embedder.embed_query(query)\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to embed query: {e}\")\n",
    "            return []\n",
    "\n",
    "class ImageEmbedder:\n",
    "    \"\"\"Handles image embedding using CLIP\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"ViT-B/32\"):\n",
    "        self.model_name = model_name\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model, self.preprocess = clip.load(model_name, device=self.device)\n",
    "        self.logger = logging.getLogger(\"image_embedder\")\n",
    "        \n",
    "    def embed_images(self, image_paths: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed a list of images from file paths\"\"\"\n",
    "        embeddings = []\n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    image_features = self.model.encode_image(image_tensor)\n",
    "                    embedding = image_features.cpu().numpy().flatten().tolist()\n",
    "                    embeddings.append(embedding)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Failed to embed image {image_path}: {e}\")\n",
    "                # Add zero embedding as fallback\n",
    "                embeddings.append([0.0] * 512)  # CLIP ViT-B/32 has 512 dims\n",
    "                \n",
    "        self.logger.info(f\"Embedded {len(image_paths)} images\")\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_image(self, image_path: str) -> List[float]:\n",
    "        \"\"\"Embed a single image\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                image_features = self.model.encode_image(image_tensor)\n",
    "                embedding = image_features.cpu().numpy().flatten().tolist()\n",
    "                return embedding\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to embed image {image_path}: {e}\")\n",
    "            return [0.0] * 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7694d2",
   "metadata": {},
   "source": [
    "## Individual Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanningAgent(BaseAgent):\n",
    "    \"\"\"Analyzes queries to determine what information is needed\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"planning_agent\", \"planner\")\n",
    "        self.planning_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a medical planning agent. Analyze the following medical question and determine what types of information are needed to provide a comprehensive answer.\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Consider:\n",
    "        1. Do we need text information from textbooks/research papers?\n",
    "        2. Do we need visual information from medical images/diagrams?\n",
    "        3. What specific medical concepts or conditions are involved?\n",
    "        4. What level of detail is required?\n",
    "        \n",
    "        Respond with a JSON object containing:\n",
    "        - \"needs_text\": boolean\n",
    "        - \"needs_images\": boolean\n",
    "        - \"medical_concepts\": list of key concepts\n",
    "        - \"query_type\": \"diagnosis\", \"treatment\", \"symptoms\", \"anatomy\", \"pathology\", etc.\n",
    "        - \"priority\": \"high\", \"medium\", \"low\"\n",
    "        - \"reasoning\": explanation of your analysis\n",
    "        \"\"\")\n",
    "        \n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        if message.message_type == \"analyze_query\":\n",
    "            self.analyze_query(message)\n",
    "    \n",
    "    def analyze_query(self, message: A2AMessage):\n",
    "        \"\"\"Analyze a medical query and determine information needs\"\"\"\n",
    "        query = message.content.get(\"query\", \"\")\n",
    "        \n",
    "        try:\n",
    "            # Use LLM to analyze the query\n",
    "            chain = self.planning_prompt | self.llm | StrOutputParser()\n",
    "            analysis = chain.invoke({\"question\": query})\n",
    "            \n",
    "            # Parse the JSON response\n",
    "            import json\n",
    "            plan = json.loads(analysis)\n",
    "            \n",
    "            # Send analysis to agent manager\n",
    "            response_content = {\n",
    "                \"original_query\": query,\n",
    "                \"analysis\": plan,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"query_analysis\",\n",
    "                content=response_content,\n",
    "                manager=message.content.get(\"manager\")\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"Analyzed query: {query[:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to analyze query: {e}\")\n",
    "            # Send error response\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"query_analysis_error\",\n",
    "                content={\"error\": str(e), \"original_query\": query},\n",
    "                manager=message.content.get(\"manager\")\n",
    "            )\n",
    "\n",
    "class TextRetrieverAgent(BaseAgent):\n",
    "    \"\"\"Retrieves relevant text information from medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store_manager: VectorStoreManager, text_embedder: TextEmbedder):\n",
    "        super().__init__(\"text_retriever\", \"retriever\")\n",
    "        self.vector_store = vector_store_manager\n",
    "        self.embedder = text_embedder\n",
    "        \n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        if message.message_type == \"retrieve_text\":\n",
    "            self.retrieve_text(message)\n",
    "    \n",
    "    def retrieve_text(self, message: A2AMessage):\n",
    "        \"\"\"Retrieve relevant text documents\"\"\"\n",
    "        query = message.content.get(\"query\", \"\")\n",
    "        top_k = message.content.get(\"top_k\", 5)\n",
    "        \n",
    "        try:\n",
    "            # Embed the query\n",
    "            query_embedding = self.embedder.embed_query(query)\n",
    "            \n",
    "            # Search the vector store\n",
    "            results = self.vector_store.search_texts(query_embedding, top_k)\n",
    "            \n",
    "            # Format results\n",
    "            formatted_results = []\n",
    "            for result in results:\n",
    "                formatted_results.append({\n",
    "                    \"id\": result[\"id\"],\n",
    "                    \"text\": result[\"text\"],\n",
    "                    \"score\": result[\"score\"],\n",
    "                    \"metadata\": result[\"metadata\"]\n",
    "                })\n",
    "            \n",
    "            # Send results back\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"text_results\",\n",
    "                content={\n",
    "                    \"query\": query,\n",
    "                    \"results\": formatted_results,\n",
    "                    \"count\": len(formatted_results)\n",
    "                },\n",
    "                manager=message.content.get(\"manager\")\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"Retrieved {len(formatted_results)} text documents for query: {query[:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to retrieve text: {e}\")\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"text_retrieval_error\",\n",
    "                content={\"error\": str(e), \"query\": query},\n",
    "                manager=message.content.get(\"manager\")\n",
    "            )\n",
    "\n",
    "class ImageRetrieverAgent(BaseAgent):\n",
    "    \"\"\"Retrieves relevant image information from medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store_manager: VectorStoreManager, image_embedder: ImageEmbedder):\n",
    "        super().__init__(\"image_retriever\", \"retriever\")\n",
    "        self.vector_store = vector_store_manager\n",
    "        self.embedder = image_embedder\n",
    "        \n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        if message.message_type == \"retrieve_images\":\n",
    "            self.retrieve_images(message)\n",
    "    \n",
    "    def retrieve_images(self, message: A2AMessage):\n",
    "        \"\"\"Retrieve relevant image documents\"\"\"\n",
    "        query = message.content.get(\"query\", \"\")\n",
    "        top_k = message.content.get(\"top_k\", 5)\n",
    "        \n",
    "        try:\n",
    "            # For image retrieval, we need to convert text query to image embedding\n",
    "            # This is a simplified approach - in practice, you might want to use\n",
    "            # a text-to-image embedding model or multimodal approach\n",
    "            query_embedding = self.embedder.embed_query(query)  # This will use text embedder\n",
    "            \n",
    "            # Search the vector store\n",
    "            results = self.vector_store.search_images(query_embedding, top_k)\n",
    "            \n",
    "            # Format results\n",
    "            formatted_results = []\n",
    "            for result in results:\n",
    "                formatted_results.append({\n",
    "                    \"id\": result[\"id\"],\n",
    "                    \"image_path\": result[\"image_path\"],\n",
    "                    \"score\": result[\"score\"],\n",
    "                    \"metadata\": result[\"metadata\"]\n",
    "                })\n",
    "            \n",
    "            # Send results back\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"image_results\",\n",
    "                content={\n",
    "                    \"query\": query,\n",
    "                    \"results\": formatted_results,\n",
    "                    \"count\": len(formatted_results)\n",
    "                },\n",
    "                manager=message.content.get(\"manager\")\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"Retrieved {len(formatted_results)} image documents for query: {query[:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to retrieve images: {e}\")\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"image_retrieval_error\",\n",
    "                content={\"error\": str(e), \"query\": query},\n",
    "                manager=message.content.get(\"manager\")\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReasonerAgent(BaseAgent):\n",
    "    \"\"\"Synthesizes information from all sources to reason about the medical question\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"reasoner_agent\", \"reasoner\")\n",
    "        self.reasoning_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a medical reasoning agent. Analyze the following information and provide a comprehensive medical reasoning.\n",
    "        \n",
    "        Original Question: {question}\n",
    "        \n",
    "        Text Information:\n",
    "        {text_info}\n",
    "        \n",
    "        Image Information:\n",
    "        {image_info}\n",
    "        \n",
    "        Query Analysis:\n",
    "        {query_analysis}\n",
    "        \n",
    "        Based on the provided information, provide:\n",
    "        1. Key medical findings from the text sources\n",
    "        2. Relevant visual information from images (if any)\n",
    "        3. Clinical reasoning and connections\n",
    "        4. Potential limitations or missing information\n",
    "        5. Confidence level in the analysis\n",
    "        \n",
    "        Be thorough but concise. Focus on medical accuracy and clinical relevance.\n",
    "        \"\"\")\n",
    "        \n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        if message.message_type == \"reason_about_query\":\n",
    "            self.reason_about_query(message)\n",
    "    \n",
    "    def reason_about_query(self, message: A2AMessage):\n",
    "        \"\"\"Synthesize information and provide medical reasoning\"\"\"\n",
    "        content = message.content\n",
    "        \n",
    "        try:\n",
    "            # Format text information\n",
    "            text_info = \"\"\n",
    "            if \"text_results\" in content:\n",
    "                text_results = content[\"text_results\"]\n",
    "                text_info = \"\\\\n\\\\n\".join([\n",
    "                    f\"Source {i+1}: {result['text'][:500]}...\" \n",
    "                    for i, result in enumerate(text_results)\n",
    "                ])\n",
    "            \n",
    "            # Format image information\n",
    "            image_info = \"\"\n",
    "            if \"image_results\" in content:\n",
    "                image_results = content[\"image_results\"]\n",
    "                image_info = \"\\\\n\\\\n\".join([\n",
    "                    f\"Image {i+1}: {result['image_path']} (Relevance: {result['score']:.3f})\" \n",
    "                    for i, result in enumerate(image_results)\n",
    "                ])\n",
    "            \n",
    "            # Create reasoning chain\n",
    "            chain = self.reasoning_prompt | self.llm | StrOutputParser()\n",
    "            \n",
    "            reasoning = chain.invoke({\n",
    "                \"question\": content.get(\"original_query\", \"\"),\n",
    "                \"text_info\": text_info,\n",
    "                \"image_info\": image_info,\n",
    "                \"query_analysis\": content.get(\"query_analysis\", {})\n",
    "            })\n",
    "            \n",
    "            # Send reasoning to draft agent\n",
    "            self.send_message(\n",
    "                receiver=\"draft_agent\",\n",
    "                message_type=\"generate_response\",\n",
    "                content={\n",
    "                    \"original_query\": content.get(\"original_query\", \"\"),\n",
    "                    \"reasoning\": reasoning,\n",
    "                    \"text_results\": content.get(\"text_results\", []),\n",
    "                    \"image_results\": content.get(\"image_results\", []),\n",
    "                    \"query_analysis\": content.get(\"query_analysis\", {})\n",
    "                },\n",
    "                manager=content.get(\"manager\")\n",
    "            )\n",
    "            \n",
    "            self.logger.info(\"Completed medical reasoning analysis\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to reason about query: {e}\")\n",
    "            self.send_message(\n",
    "                receiver=\"draft_agent\",\n",
    "                message_type=\"reasoning_error\",\n",
    "                content={\"error\": str(e), \"original_query\": content.get(\"original_query\", \"\")},\n",
    "                manager=content.get(\"manager\")\n",
    "            )\n",
    "\n",
    "class DraftAgent(BaseAgent):\n",
    "    \"\"\"Generates final responses for doctors\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"draft_agent\", \"draft\")\n",
    "        self.draft_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a medical AI assistant providing information to doctors. Generate a comprehensive, accurate, and clinically relevant response.\n",
    "        \n",
    "        Original Question: {question}\n",
    "        \n",
    "        Medical Reasoning:\n",
    "        {reasoning}\n",
    "        \n",
    "        Supporting Evidence:\n",
    "        Text Sources: {text_evidence}\n",
    "        Image Sources: {image_evidence}\n",
    "        \n",
    "        Instructions:\n",
    "        1. Provide a clear, structured answer to the medical question\n",
    "        2. Include relevant clinical details and context\n",
    "        3. Cite specific information from the sources when appropriate\n",
    "        4. Note any limitations or areas where more information might be needed\n",
    "        5. Use professional medical language appropriate for healthcare providers\n",
    "        6. Include disclaimers about the limitations of AI-generated medical information\n",
    "        \n",
    "        Format your response as a professional medical consultation note.\n",
    "        \"\"\")\n",
    "        \n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        if message.message_type == \"generate_response\":\n",
    "            self.generate_response(message)\n",
    "        elif message.message_type == \"reasoning_error\":\n",
    "            self.handle_reasoning_error(message)\n",
    "    \n",
    "    def generate_response(self, message: A2AMessage):\n",
    "        \"\"\"Generate the final medical response\"\"\"\n",
    "        content = message.content\n",
    "        \n",
    "        try:\n",
    "            # Format text evidence\n",
    "            text_evidence = \"\"\n",
    "            if content.get(\"text_results\"):\n",
    "                text_evidence = \"\\\\n\\\\n\".join([\n",
    "                    f\"• {result['text'][:200]}... (Source: {result.get('metadata', {}).get('source', 'Unknown')})\" \n",
    "                    for result in content[\"text_results\"][:3]  # Limit to top 3\n",
    "                ])\n",
    "            \n",
    "            # Format image evidence\n",
    "            image_evidence = \"\"\n",
    "            if content.get(\"image_results\"):\n",
    "                image_evidence = \"\\\\n\".join([\n",
    "                    f\"• {result['image_path']} (Relevance: {result['score']:.3f})\" \n",
    "                    for result in content[\"image_results\"][:3]  # Limit to top 3\n",
    "                ])\n",
    "            \n",
    "            # Generate response\n",
    "            chain = self.draft_prompt | self.llm | StrOutputParser()\n",
    "            \n",
    "            response = chain.invoke({\n",
    "                \"question\": content.get(\"original_query\", \"\"),\n",
    "                \"reasoning\": content.get(\"reasoning\", \"\"),\n",
    "                \"text_evidence\": text_evidence,\n",
    "                \"image_evidence\": image_evidence\n",
    "            })\n",
    "            \n",
    "            # Send final response to agent manager\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"final_response\",\n",
    "                content={\n",
    "                    \"original_query\": content.get(\"original_query\", \"\"),\n",
    "                    \"response\": response,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"sources_used\": {\n",
    "                        \"text_count\": len(content.get(\"text_results\", [])),\n",
    "                        \"image_count\": len(content.get(\"image_results\", []))\n",
    "                    }\n",
    "                },\n",
    "                manager=content.get(\"manager\")\n",
    "            )\n",
    "            \n",
    "            self.logger.info(\"Generated final medical response\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to generate response: {e}\")\n",
    "            self.send_message(\n",
    "                receiver=\"agent_manager\",\n",
    "                message_type=\"response_error\",\n",
    "                content={\"error\": str(e), \"original_query\": content.get(\"original_query\", \"\")},\n",
    "                manager=content.get(\"manager\")\n",
    "            )\n",
    "    \n",
    "    def handle_reasoning_error(self, message: A2AMessage):\n",
    "        \"\"\"Handle cases where reasoning failed\"\"\"\n",
    "        content = message.content\n",
    "        \n",
    "        error_response = f\"\"\"\n",
    "        I apologize, but I encountered an error while processing your medical question: \"{content.get('original_query', '')}\"\n",
    "        \n",
    "        Error: {content.get('error', 'Unknown error')}\n",
    "        \n",
    "        Please try rephrasing your question or contact support if the issue persists.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.send_message(\n",
    "            receiver=\"agent_manager\",\n",
    "            message_type=\"final_response\",\n",
    "            content={\n",
    "                \"original_query\": content.get(\"original_query\", \"\"),\n",
    "                \"response\": error_response,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"error\": True\n",
    "            },\n",
    "            manager=content.get(\"manager\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14170dd",
   "metadata": {},
   "source": [
    "## Agent Manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentManager:\n",
    "    \"\"\"Manages all agents and coordinates the medical knowledge system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(\"agent_manager\")\n",
    "        \n",
    "        # Initialize components\n",
    "        self.vector_store_manager = VectorStoreManager()\n",
    "        self.text_embedder = TextEmbedder()\n",
    "        self.image_embedder = ImageEmbedder()\n",
    "        \n",
    "        # Initialize agents\n",
    "        self.planning_agent = PlanningAgent()\n",
    "        self.text_retriever = TextRetrieverAgent(self.vector_store_manager, self.text_embedder)\n",
    "        self.image_retriever = ImageRetrieverAgent(self.vector_store_manager, self.image_embedder)\n",
    "        self.reasoner_agent = ReasonerAgent()\n",
    "        self.draft_agent = DraftAgent()\n",
    "        \n",
    "        # Agent registry\n",
    "        self.agents = {\n",
    "            \"planning_agent\": self.planning_agent,\n",
    "            \"text_retriever\": self.text_retriever,\n",
    "            \"image_retriever\": self.image_retriever,\n",
    "            \"reasoner_agent\": self.reasoner_agent,\n",
    "            \"draft_agent\": self.draft_agent\n",
    "        }\n",
    "        \n",
    "        # State tracking\n",
    "        self.active_queries = {}\n",
    "        self.query_results = {}\n",
    "        \n",
    "        self.logger.info(\"Agent Manager initialized with all agents\")\n",
    "    \n",
    "    def deliver_message(self, message: A2AMessage):\n",
    "        \"\"\"Deliver a message to the appropriate agent\"\"\"\n",
    "        if message.receiver in self.agents:\n",
    "            self.agents[message.receiver].receive_message(message)\n",
    "        else:\n",
    "            self.logger.warning(f\"Unknown agent: {message.receiver}\")\n",
    "    \n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a medical query through the agent system\"\"\"\n",
    "        query_id = str(uuid.uuid4())\n",
    "        self.logger.info(f\"Processing query {query_id}: {query[:50]}...\")\n",
    "        \n",
    "        # Initialize query state\n",
    "        self.active_queries[query_id] = {\n",
    "            \"query\": query,\n",
    "            \"status\": \"processing\",\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"results\": {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Send query to planning agent\n",
    "            self.planning_agent.send_message(\n",
    "                receiver=\"planning_agent\",\n",
    "                message_type=\"analyze_query\",\n",
    "                content={\n",
    "                    \"query\": query,\n",
    "                    \"query_id\": query_id,\n",
    "                    \"manager\": self\n",
    "                },\n",
    "                manager=self\n",
    "            )\n",
    "            \n",
    "            # Process messages until we get a final response\n",
    "            max_iterations = 20\n",
    "            iteration = 0\n",
    "            \n",
    "            while iteration < max_iterations:\n",
    "                # Process all agent mailboxes\n",
    "                for agent in self.agents.values():\n",
    "                    agent.process_messages()\n",
    "                \n",
    "                # Check if we have a final response\n",
    "                if query_id in self.query_results:\n",
    "                    break\n",
    "                    \n",
    "                iteration += 1\n",
    "                if iteration >= max_iterations:\n",
    "                    self.logger.warning(f\"Query {query_id} timed out after {max_iterations} iterations\")\n",
    "                    break\n",
    "            \n",
    "            # Return results\n",
    "            if query_id in self.query_results:\n",
    "                result = self.query_results[query_id]\n",
    "                result[\"query_id\"] = query_id\n",
    "                result[\"processing_time\"] = (datetime.now() - self.active_queries[query_id][\"start_time\"]).total_seconds()\n",
    "                return result\n",
    "            else:\n",
    "                return {\n",
    "                    \"query_id\": query_id,\n",
    "                    \"error\": \"Query processing timed out\",\n",
    "                    \"status\": \"error\"\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing query {query_id}: {e}\")\n",
    "            return {\n",
    "                \"query_id\": query_id,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if query_id in self.active_queries:\n",
    "                del self.active_queries[query_id]\n",
    "    \n",
    "    def handle_message(self, message: A2AMessage):\n",
    "        \"\"\"Handle messages from agents\"\"\"\n",
    "        if message.receiver == \"agent_manager\":\n",
    "            if message.message_type == \"query_analysis\":\n",
    "                self.handle_query_analysis(message)\n",
    "            elif message.message_type == \"text_results\":\n",
    "                self.handle_text_results(message)\n",
    "            elif message.message_type == \"image_results\":\n",
    "                self.handle_image_results(message)\n",
    "            elif message.message_type == \"final_response\":\n",
    "                self.handle_final_response(message)\n",
    "            else:\n",
    "                self.logger.warning(f\"Unknown message type: {message.message_type}\")\n",
    "    \n",
    "    def handle_query_analysis(self, message: A2AMessage):\n",
    "        \"\"\"Handle query analysis from planning agent\"\"\"\n",
    "        content = message.content\n",
    "        query_id = content.get(\"query_id\")\n",
    "        analysis = content.get(\"analysis\", {})\n",
    "        \n",
    "        if query_id not in self.active_queries:\n",
    "            return\n",
    "            \n",
    "        self.active_queries[query_id][\"results\"][\"analysis\"] = analysis\n",
    "        \n",
    "        # Determine what retrievers to activate\n",
    "        if analysis.get(\"needs_text\", False):\n",
    "            self.text_retriever.send_message(\n",
    "                receiver=\"text_retriever\",\n",
    "                message_type=\"retrieve_text\",\n",
    "                content={\n",
    "                    \"query\": self.active_queries[query_id][\"query\"],\n",
    "                    \"query_id\": query_id,\n",
    "                    \"top_k\": 5,\n",
    "                    \"manager\": self\n",
    "                },\n",
    "                manager=self\n",
    "            )\n",
    "        \n",
    "        if analysis.get(\"needs_images\", False):\n",
    "            self.image_retriever.send_message(\n",
    "                receiver=\"image_retriever\",\n",
    "                message_type=\"retrieve_images\",\n",
    "                content={\n",
    "                    \"query\": self.active_queries[query_id][\"query\"],\n",
    "                    \"query_id\": query_id,\n",
    "                    \"top_k\": 3,\n",
    "                    \"manager\": self\n",
    "                },\n",
    "                manager=self\n",
    "            )\n",
    "        \n",
    "        # If no retrievers needed, send directly to reasoner\n",
    "        if not analysis.get(\"needs_text\", False) and not analysis.get(\"needs_images\", False):\n",
    "            self.reasoner_agent.send_message(\n",
    "                receiver=\"reasoner_agent\",\n",
    "                message_type=\"reason_about_query\",\n",
    "                content={\n",
    "                    \"original_query\": self.active_queries[query_id][\"query\"],\n",
    "                    \"query_id\": query_id,\n",
    "                    \"query_analysis\": analysis,\n",
    "                    \"text_results\": [],\n",
    "                    \"image_results\": [],\n",
    "                    \"manager\": self\n",
    "                },\n",
    "                manager=self\n",
    "            )\n",
    "    \n",
    "    def handle_text_results(self, message: A2AMessage):\n",
    "        \"\"\"Handle text retrieval results\"\"\"\n",
    "        content = message.content\n",
    "        query_id = content.get(\"query_id\")\n",
    "        \n",
    "        if query_id not in self.active_queries:\n",
    "            return\n",
    "            \n",
    "        self.active_queries[query_id][\"results\"][\"text_results\"] = content.get(\"results\", [])\n",
    "        self.check_and_trigger_reasoner(query_id)\n",
    "    \n",
    "    def handle_image_results(self, message: A2AMessage):\n",
    "        \"\"\"Handle image retrieval results\"\"\"\n",
    "        content = message.content\n",
    "        query_id = content.get(\"query_id\")\n",
    "        \n",
    "        if query_id not in self.active_queries:\n",
    "            return\n",
    "            \n",
    "        self.active_queries[query_id][\"results\"][\"image_results\"] = content.get(\"results\", [])\n",
    "        self.check_and_trigger_reasoner(query_id)\n",
    "    \n",
    "    def check_and_trigger_reasoner(self, query_id: str):\n",
    "        \"\"\"Check if we have all needed results and trigger reasoner\"\"\"\n",
    "        if query_id not in self.active_queries:\n",
    "            return\n",
    "            \n",
    "        query_data = self.active_queries[query_id]\n",
    "        results = query_data[\"results\"]\n",
    "        analysis = results.get(\"analysis\", {})\n",
    "        \n",
    "        # Check if we have all needed data\n",
    "        needs_text = analysis.get(\"needs_text\", False)\n",
    "        needs_images = analysis.get(\"needs_images\", False)\n",
    "        \n",
    "        has_text = \"text_results\" in results\n",
    "        has_images = \"image_results\" in results\n",
    "        \n",
    "        # Trigger reasoner if we have all needed data\n",
    "        if (not needs_text or has_text) and (not needs_images or has_images):\n",
    "            self.reasoner_agent.send_message(\n",
    "                receiver=\"reasoner_agent\",\n",
    "                message_type=\"reason_about_query\",\n",
    "                content={\n",
    "                    \"original_query\": query_data[\"query\"],\n",
    "                    \"query_id\": query_id,\n",
    "                    \"query_analysis\": analysis,\n",
    "                    \"text_results\": results.get(\"text_results\", []),\n",
    "                    \"image_results\": results.get(\"image_results\", []),\n",
    "                    \"manager\": self\n",
    "                },\n",
    "                manager=self\n",
    "            )\n",
    "    \n",
    "    def handle_final_response(self, message: A2AMessage):\n",
    "        \"\"\"Handle final response from draft agent\"\"\"\n",
    "        content = message.content\n",
    "        query_id = content.get(\"query_id\")\n",
    "        \n",
    "        if query_id not in self.active_queries:\n",
    "            return\n",
    "            \n",
    "        # Store final result\n",
    "        self.query_results[query_id] = {\n",
    "            \"query\": content.get(\"original_query\", \"\"),\n",
    "            \"response\": content.get(\"response\", \"\"),\n",
    "            \"timestamp\": content.get(\"timestamp\"),\n",
    "            \"sources_used\": content.get(\"sources_used\", {}),\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"Query {query_id} completed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb55ca8",
   "metadata": {},
   "source": [
    "## Data Ingestion and Main System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"Handles document loading, chunking, and processing for medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\\\n\\\\n\", \"\\\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        self.logger = logging.getLogger(\"document_processor\")\n",
    "    \n",
    "    def process_pdf_directory(self, directory_path: str) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
    "        \"\"\"Process all PDFs in a directory\"\"\"\n",
    "        self.logger.info(f\"Processing PDFs in directory: {directory_path}\")\n",
    "        \n",
    "        # Load all PDFs\n",
    "        loader = DirectoryLoader(\n",
    "            directory_path,\n",
    "            glob=\"**/*.pdf\",\n",
    "            loader_cls=PyPDFLoader\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Split into chunks\n",
    "        chunks = self.text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Extract texts and metadata\n",
    "        texts = []\n",
    "        metadata = []\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            texts.append(chunk.page_content)\n",
    "            metadata.append({\n",
    "                \"source\": chunk.metadata.get(\"source\", \"unknown\"),\n",
    "                \"page\": chunk.metadata.get(\"page\", 0),\n",
    "                \"chunk_id\": str(uuid.uuid4())\n",
    "            })\n",
    "        \n",
    "        self.logger.info(f\"Processed {len(texts)} text chunks from {len(documents)} documents\")\n",
    "        return texts, metadata\n",
    "    \n",
    "    def extract_images_from_pdfs(self, directory_path: str) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
    "        \"\"\"Extract images from PDFs (simplified implementation)\"\"\"\n",
    "        # This is a simplified implementation\n",
    "        # In practice, you'd use libraries like PyMuPDF or pdf2image\n",
    "        self.logger.info(f\"Extracting images from PDFs in: {directory_path}\")\n",
    "        \n",
    "        # For now, return empty lists - you can implement actual image extraction\n",
    "        # using libraries like PyMuPDF, pdf2image, or similar\n",
    "        image_paths = []\n",
    "        image_metadata = []\n",
    "        \n",
    "        self.logger.warning(\"Image extraction not implemented - returning empty results\")\n",
    "        return image_paths, image_metadata\n",
    "\n",
    "class MedicalKnowledgeSystem:\n",
    "    \"\"\"Main system class that orchestrates the entire medical knowledge system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(\"medical_system\")\n",
    "        \n",
    "        # Initialize components\n",
    "        self.vector_store_manager = VectorStoreManager()\n",
    "        self.text_embedder = TextEmbedder()\n",
    "        self.image_embedder = ImageEmbedder()\n",
    "        self.document_processor = DocumentProcessor()\n",
    "        self.agent_manager = AgentManager()\n",
    "        \n",
    "        # System state\n",
    "        self.is_initialized = False\n",
    "        self.data_ingested = False\n",
    "        \n",
    "        self.logger.info(\"Medical Knowledge System initialized\")\n",
    "    \n",
    "    def setup_vector_store(self) -> bool:\n",
    "        \"\"\"Set up the Milvus vector store\"\"\"\n",
    "        try:\n",
    "            success = self.vector_store_manager.create_collections()\n",
    "            if success:\n",
    "                self.is_initialized = True\n",
    "                self.logger.info(\"Vector store setup completed\")\n",
    "            else:\n",
    "                self.logger.error(\"Failed to setup vector store\")\n",
    "            return success\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error setting up vector store: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def ingest_documents(self, data_directory: str) -> bool:\n",
    "        \"\"\"Ingest medical documents into the system\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            self.logger.error(\"Vector store not initialized. Call setup_vector_store() first.\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Process text documents\n",
    "            self.logger.info(\"Processing text documents...\")\n",
    "            texts, text_metadata = self.document_processor.process_pdf_directory(data_directory)\n",
    "            \n",
    "            if texts:\n",
    "                # Embed texts\n",
    "                text_embeddings = self.text_embedder.embed_texts(texts)\n",
    "                \n",
    "                # Insert into vector store\n",
    "                success = self.vector_store_manager.insert_texts(texts, text_embeddings, text_metadata)\n",
    "                if not success:\n",
    "                    self.logger.error(\"Failed to insert text documents\")\n",
    "                    return False\n",
    "                \n",
    "                self.logger.info(f\"Successfully ingested {len(texts)} text chunks\")\n",
    "            \n",
    "            # Process images (if any)\n",
    "            self.logger.info(\"Processing images...\")\n",
    "            image_paths, image_metadata = self.document_processor.extract_images_from_pdfs(data_directory)\n",
    "            \n",
    "            if image_paths:\n",
    "                # Embed images\n",
    "                image_embeddings = self.image_embedder.embed_images(image_paths)\n",
    "                \n",
    "                # Insert into vector store\n",
    "                success = self.vector_store_manager.insert_images(image_paths, image_embeddings, image_metadata)\n",
    "                if not success:\n",
    "                    self.logger.error(\"Failed to insert image documents\")\n",
    "                    return False\n",
    "                \n",
    "                self.logger.info(f\"Successfully ingested {len(image_paths)} images\")\n",
    "            \n",
    "            self.data_ingested = True\n",
    "            self.logger.info(\"Document ingestion completed successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error ingesting documents: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def ask_question(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Ask a medical question to the system\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            return {\"error\": \"System not initialized. Call setup_vector_store() first.\"}\n",
    "        \n",
    "        if not self.data_ingested:\n",
    "            return {\"error\": \"No data ingested. Call ingest_documents() first.\"}\n",
    "        \n",
    "        try:\n",
    "            # Process the query through the agent system\n",
    "            result = self.agent_manager.process_query(question)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing question: {e}\")\n",
    "            return {\"error\": str(e), \"status\": \"error\"}\n",
    "    \n",
    "    def get_system_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the current status of the system\"\"\"\n",
    "        return {\n",
    "            \"initialized\": self.is_initialized,\n",
    "            \"data_ingested\": self.data_ingested,\n",
    "            \"vector_store_connected\": self.vector_store_manager.connect(),\n",
    "            \"agents_ready\": len(self.agent_manager.agents),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50553fa6",
   "metadata": {},
   "source": [
    "## Usage Examples and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df095e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the medical knowledge system\n",
    "medical_system = MedicalKnowledgeSystem()\n",
    "\n",
    "# Check system status\n",
    "print(\"System Status:\")\n",
    "print(json.dumps(medical_system.get_system_status(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Milvus vector store\n",
    "print(\"Setting up vector store...\")\n",
    "setup_success = medical_system.setup_vector_store()\n",
    "\n",
    "if setup_success:\n",
    "    print(\"✅ Vector store setup successful!\")\n",
    "else:\n",
    "    print(\"❌ Vector store setup failed. Make sure Milvus is running.\")\n",
    "    print(\"To start Milvus: docker run -d --name milvus-standalone -p 19530:19530 milvusdb/milvus:latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest medical documents\n",
    "# Replace with your actual data directory path\n",
    "data_directory = \"./FINAL DATASET/\"  # Update this path to your data directory\n",
    "\n",
    "print(f\"Ingesting documents from: {data_directory}\")\n",
    "ingestion_success = medical_system.ingest_documents(data_directory)\n",
    "\n",
    "if ingestion_success:\n",
    "    print(\"✅ Document ingestion successful!\")\n",
    "    print(\"System is ready to answer medical questions.\")\n",
    "else:\n",
    "    print(\"❌ Document ingestion failed.\")\n",
    "    print(\"Please check that the data directory exists and contains PDF files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eed9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the system with medical questions\n",
    "test_questions = [\n",
    "    \"What are the symptoms of pneumonia?\",\n",
    "    \"How is diabetes diagnosed?\",\n",
    "    \"What are the treatment options for hypertension?\",\n",
    "    \"Describe the anatomy of the heart\",\n",
    "    \"What are the side effects of common antibiotics?\"\n",
    "]\n",
    "\n",
    "print(\"Testing the medical knowledge system...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\\\nQuestion {i}: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        result = medical_system.ask_question(question)\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"❌ Error: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"✅ Response:\")\n",
    "            print(result.get(\"response\", \"No response generated\"))\n",
    "            print(f\"\\\\nSources used: {result.get('sources_used', {})}\")\n",
    "            print(f\"Processing time: {result.get('processing_time', 0):.2f} seconds\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception: {e}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6754f",
   "metadata": {},
   "source": [
    "## Interactive Usage\n",
    "\n",
    "You can now ask questions interactively to the medical knowledge system. The system will:\n",
    "\n",
    "1. **Analyze your question** using the Planning Agent to determine what information is needed\n",
    "2. **Retrieve relevant text** from medical textbooks and research papers\n",
    "3. **Retrieve relevant images** from medical documents (when available)\n",
    "4. **Reason about the information** using the Reasoner Agent to synthesize findings\n",
    "5. **Generate a comprehensive response** using the Draft Agent\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "# Ask a specific medical question\n",
    "question = \"What are the early signs of myocardial infarction?\"\n",
    "result = medical_system.ask_question(question)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['response']}\")\n",
    "print(f\"Sources: {result['sources_used']}\")\n",
    "```\n",
    "\n",
    "### System Features:\n",
    "\n",
    "- **Multi-Agent Architecture**: Each agent has a specific role in processing medical queries\n",
    "- **A2A Communication**: Agents communicate through structured messages\n",
    "- **MCP Integration**: Model Context Protocol for standardized communication\n",
    "- **Vector Search**: Semantic search through medical documents using embeddings\n",
    "- **Multi-modal Support**: Handles both text and image information\n",
    "- **Medical Reasoning**: Specialized reasoning for medical domain knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing - ask your own medical questions here\n",
    "# Uncomment and modify the question below to test the system\n",
    "\n",
    "# question = \"What are the treatment protocols for sepsis?\"\n",
    "# result = medical_system.ask_question(question)\n",
    "# print(f\"Question: {question}\")\n",
    "# print(f\"Answer: {result['response']}\")\n",
    "# print(f\"Sources: {result['sources_used']}\")\n",
    "\n",
    "print(\"System ready for interactive use!\")\n",
    "print(\"Uncomment the code above to ask your own medical questions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de169b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f58c4524",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
