{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c2e853",
   "metadata": {},
   "source": [
    "# Information\n",
    "- Milvus running on local host. Need to change it when placing on cloud\n",
    "- Only one PDF was loaded into milvus, so need to update it\n",
    "\n",
    "\n",
    "### Information on architecture built\n",
    "- MILVUS STORAGE name: `medical_knowledge_base_v2`\n",
    "- embedding model: `sentence-transformers/all-MiniLM-L6-v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62ec8c",
   "metadata": {},
   "source": [
    "# ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from pathlib import Path\n",
    "import os\n",
    "import logging\n",
    "from typing import List, Set, Dict, Any\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Document loading\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vector database\n",
    "from pymilvus import connections, utility\n",
    "from pymilvus.orm.collection import Collection\n",
    "from pymilvus.exceptions import MilvusException\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus\n",
    "\n",
    "# Constants\n",
    "MILVUS_COLLECTION_NAME = \"medical_knowledge_base_v2\"\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def connect_to_milvus(host: str = \"localhost\", port: str = \"19530\") -> bool:\n",
    "    \"\"\"Establish connection to Milvus server with error handling.\"\"\"\n",
    "    try:\n",
    "        # First disconnect to reset any existing connections\n",
    "        try:\n",
    "            connections.disconnect(\"default\")\n",
    "        except:\n",
    "            pass  # Ignore if no connection exists\n",
    "        \n",
    "        # Connect to Milvus\n",
    "        connections.connect(host=host, port=port)\n",
    "        \n",
    "        # Verify connection by listing collections\n",
    "        utility.list_collections()\n",
    "        logger.info(f\"✅ Connected to Milvus server at {host}:{port}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to connect to Milvus: {str(e)}\")\n",
    "        return False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def load_pdfs(data_directory: str) -> List:\n",
    "    \"\"\"Load PDF documents with error handling.\"\"\"\n",
    "    try:\n",
    "        # Find PDFs on disk\n",
    "        pdf_files = list(Path(data_directory).rglob(\"*.pdf\"))\n",
    "        logger.info(f\"Found {len(pdf_files)} PDF files:\")\n",
    "        for p in pdf_files:\n",
    "            logger.info(f\"  {p.name}\")\n",
    "        \n",
    "        # Load every page as a Document\n",
    "        loader = DirectoryLoader(\n",
    "            data_directory, \n",
    "            glob=\"**/*.pdf\", \n",
    "            loader_cls=PyMuPDFLoader)\n",
    "        \n",
    "        docs = loader.load()\n",
    "        logger.info(f\"✅ Loaded {len(docs)} pages from your PDFs\")\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error loading PDFs: {str(e)}\")\n",
    "        return []'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd6eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def connect_to_milvus(host: str = \"localhost\", port: str = \"19530\") -> bool:\n",
    "    \"\"\"Establish connection to Milvus server with error handling.\"\"\"\n",
    "    try:\n",
    "        # First disconnect to reset any existing connections\n",
    "        try:\n",
    "            connections.disconnect(\"default\")\n",
    "        except:\n",
    "            pass  # Ignore if no connection exists\n",
    "        \n",
    "        # Connect to Milvus\n",
    "        connections.connect(host=host, port=port)\n",
    "        \n",
    "        # Verify connection by listing collections\n",
    "        utility.list_collections()\n",
    "        logger.info(f\"✅ Connected to Milvus server at {host}:{port}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to connect to Milvus: {str(e)}\")\n",
    "        return False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_existing_sources(collection_name: str) -> Set[str]:\n",
    "    \"\"\"Retrieve existing document sources from Milvus collection with pagination.\"\"\"\n",
    "    try:\n",
    "        col = Collection(collection_name)\n",
    "        col.load()\n",
    "        \n",
    "        # Get total count of entities\n",
    "        count = col.num_entities\n",
    "        logger.info(f\"Total entities in collection: {count}\")\n",
    "        \n",
    "        # Use pagination to handle large collections\n",
    "        batch_size = 10000\n",
    "        offset = 0\n",
    "        all_sources = set()\n",
    "        \n",
    "        while offset < count:\n",
    "            results = col.query(\n",
    "                expr=\"\",\n",
    "                output_fields=[\"source\"],\n",
    "                limit=batch_size,\n",
    "                offset=offset\n",
    "            )\n",
    "            sources = {row[\"source\"] for row in results if \"source\" in row}\n",
    "            all_sources.update(sources)\n",
    "            offset += batch_size\n",
    "            \n",
    "        logger.info(f\"✅ Retrieved {len(all_sources)} unique source paths from Milvus\")\n",
    "        return all_sources\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error retrieving existing sources: {str(e)}\")\n",
    "        return set()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def filter_and_chunk_documents(docs, existing_sources: Set[str], chunk_size: int, chunk_overlap: int):\n",
    "    \"\"\"Filter out already processed documents and chunk new ones.\"\"\"\n",
    "    try:\n",
    "        # Filter out docs whose source PDF is already in Milvus\n",
    "        new_docs = [doc for doc in docs if doc.metadata[\"source\"] not in existing_sources]\n",
    "        logger.info(f\"🛡  Skipping {len(docs) - len(new_docs)} pages already uploaded\")\n",
    "        logger.info(f\"🔄  Will process {len(new_docs)} new pages\")\n",
    "        \n",
    "        if not new_docs:\n",
    "            logger.info(\"No new documents to process.\")\n",
    "            return []\n",
    "            \n",
    "        # Chunk only new pages\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        chunks = splitter.split_documents(new_docs)\n",
    "        logger.info(f\"✅  Created {len(chunks)} chunks from new documents\")\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error filtering and chunking documents: {str(e)}\")\n",
    "        return []'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def add_to_vector_store(chunks, collection_name: str, embedding_model: str, host: str, port: str):\n",
    "    \"\"\"Add document chunks to Milvus vector store with error handling.\"\"\"\n",
    "    if not chunks:\n",
    "        logger.info(\"No chunks to add to vector store.\")\n",
    "        return False\n",
    "        \n",
    "    try:\n",
    "        # Initialize embedding model\n",
    "        start_time = time.time()\n",
    "        embedder = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        logger.info(f\"Initialized embedder: {embedding_model}\")\n",
    "        \n",
    "        try:\n",
    "            # Try to connect to an existing Milvus collection\n",
    "            vector_store = Milvus(\n",
    "                embedding_function=embedder,\n",
    "                collection_name=collection_name,\n",
    "                connection_args={\"host\": host, \"port\": port}\n",
    "            )\n",
    "            vector_store.add_documents(chunks)\n",
    "            logger.info(f\"✅ Added {len(chunks)} chunks to existing collection '{collection_name}'\")\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Creating new collection: {str(e)}\")\n",
    "            # If collection doesn't exist, create it and insert\n",
    "            vector_store = Milvus.from_documents(\n",
    "                documents=chunks,\n",
    "                embedding=embedder,\n",
    "                collection_name=collection_name,\n",
    "                connection_args={\"host\": host, \"port\": port}\n",
    "            )\n",
    "            logger.info(f\"✅ Created new collection '{collection_name}' with {len(chunks)} chunks\")\n",
    "        \n",
    "        # Log performance metrics\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Processing took {elapsed_time:.2f} seconds ({len(chunks)/elapsed_time:.2f} chunks/second)\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error adding chunks to vector store: {str(e)}\")\n",
    "        return False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd39862",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def main():\n",
    "    \"\"\"Main function to orchestrate the PDF loading and vector storage process.\"\"\"\n",
    "    # Configuration - update these for cloud deployment\n",
    "    data_directory = \"/Users/brunamedeiros/Documents/University of Chicago/Spring 2025 - Capstone I/FINAL DATASET\"\n",
    "    host = \"localhost\"  # Change for cloud deployment\n",
    "    port = \"19530\"      # Change for cloud deployment\n",
    "    \n",
    "    # Connect to Milvus\n",
    "    if not connect_to_milvus(host, port):\n",
    "        logger.error(\"Exiting due to Milvus connection failure\")\n",
    "        return\n",
    "    \n",
    "    # Load PDFs\n",
    "    docs = load_pdfs(data_directory)\n",
    "    if not docs:\n",
    "        logger.error(\"Exiting due to PDF loading failure\")\n",
    "        return\n",
    "    \n",
    "    # Get existing sources from Milvus\n",
    "    existing_sources = get_existing_sources(MILVUS_COLLECTION_NAME)\n",
    "    \n",
    "    # Filter and chunk documents\n",
    "    chunks = filter_and_chunk_documents(docs, existing_sources, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "    \n",
    "    # Add to vector store\n",
    "    success = add_to_vector_store(chunks, MILVUS_COLLECTION_NAME, EMBEDDING_MODEL, host, port)\n",
    "    \n",
    "    # Confirm total stored vectors\n",
    "    try:\n",
    "        collection = Collection(MILVUS_COLLECTION_NAME)\n",
    "        logger.info(f\"✅ Total vectors stored: {collection.num_entities}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error checking collection size: {str(e)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0647a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if __name__ == \"__main__\":\n",
    "    main()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828ebea",
   "metadata": {},
   "source": [
    "--- \n",
    "# Loading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5bac1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embed + Store in Milvus\n",
    "from pymilvus import connections\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from pymilvus import connections, utility\n",
    "from pymilvus import Collection\n",
    "\n",
    "# Visualization \n",
    "from pymilvus.orm.collection import Collection\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41006fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"/Users/brunamedeiros/Documents/University of Chicago/Spring 2025 - Capstone I/FINAL DATASET\"\n",
    "collection_name = \"medical_knowledge_base_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "958d1a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 PDF files:\n",
      "   s00261-019-02302-x.pdf\n",
      "   LI-RADS US Surveillance v2024 Core.pdf\n",
      "   PIRADS V2-1.pdf\n",
      "   Diagnostic Imaging Genitourinary ( PDFDrive ).pdf\n",
      "   Radiology Illustrated_ Hepatobiliary and Pancreatic Radiology ( PDFDrive ).pdf\n",
      "   Diagnostic Imaging_ Abdomen_ Published by Amirsys® ( PDFDrive ).pdf\n",
      "   1-s2.0-S0720048X23000712-main.pdf\n",
      "   prostatemri2.pdf\n",
      "   LI-RADS CTMR Radiation TRA v2024 Core.pdf\n",
      "   Liver imaging _ MRI with CT correlation ( PDFDrive ).pdf\n",
      "   Reporting _ RADS - Reporting and Data Systems Support.pdf\n",
      "   LIRADS Lexicon Table.pdf\n",
      "   Getting Started _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Imaging Features _ RADS - Reporting and Data Systems Support.pdf\n",
      "   CT and MRI of the Whole Body, 2-Volume Set, 6e, Volume I ( PDFDrive ).pdf\n",
      "   Mayo Clinic Gastrointestinal Imaging Review ( PDFDrive ).pdf\n",
      "   Management _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Gastrointestinal Imaging_ The Requisites (Requisites in Radiology) 3rd ed ( PDFDrive ).pdf\n",
      "   LI-RADS CTMR Nonradiation TRA v2024 Core.pdf\n",
      "   Treatment Response _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Genitourinary Radiology_ Radiology Requisites Series ( PDFDrive ) (1).pdf\n",
      "   LI-RADS 2018 Core.pdf\n",
      "   Diagnostic Categories _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Diagnostic Imaging_ Gastrointestinal ( PDFDrive ).pdf\n",
      "   What's New in v2018 _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Technique _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Application _ RADS - Reporting and Data Systems Support.pdf\n",
      "   Diagnosis _ RADS - Reporting and Data Systems Support.pdf\n",
      "   MRI of the prostate_ a practical approach ( PDFDrive ).pdf\n",
      "   westphalen-et-al-2020-variability-of-the-positive-predictive-value-of-pi-rads-for-prostate-mri-across-26-centers.pdf\n"
     ]
    }
   ],
   "source": [
    "# Find PDFs on disk\n",
    "pdf_files = list(Path(data_directory).rglob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for p in pdf_files:\n",
    "    print(\"  \", p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2e964d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 7560 pages from your PDFs\n"
     ]
    }
   ],
   "source": [
    "# Load every page as a Document\n",
    "loader = DirectoryLoader(\n",
    "    data_directory, \n",
    "    glob=\"**/*.pdf\", \n",
    "    loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()\n",
    "print(f\"\\nLoaded {len(docs)} pages from your PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45f52676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert full path into just filename\n",
    "for doc in docs:\n",
    "    path = Path(doc.metadata[\"source\"])\n",
    "    doc.metadata[\"source\"] = path.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c92c6",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1417ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Milvus\n",
    "connections.disconnect(\"default\")  # force reset\n",
    "connections.connect(host=\"localhost\", port=\"19530\")\n",
    "#print(utility.list_collections())  # confirm it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ad199",
   "metadata": {},
   "source": [
    "- pull all existing `source` field values from Milvus collection\n",
    "- Drop any page whoe `doc.metadata[\"source\"]` matches one of those, to never re-add the same PDF page twice\n",
    "- split *only* new pages into `chunks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5eba0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ No existing collection — processing all pages\n"
     ]
    }
   ],
   "source": [
    "#  Deduplication: only keep docs with new 'source'\n",
    "if utility.has_collection(collection_name):\n",
    "    col      = Collection(collection_name)\n",
    "    existing = col.query(expr=\"\", output_fields=[\"source\"], limit=16384)\n",
    "    seen     = {r[\"source\"] for r in existing}\n",
    "    new_docs = [doc for doc in docs if doc.metadata[\"source\"] not in seen]\n",
    "    print(f\"🛡  Skipping {len(docs) - len(new_docs)} pages already uploaded\")\n",
    "else:\n",
    "    new_docs = docs\n",
    "    print(\"⚡ No existing collection — processing all pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0939be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# query existing \\'source\\' metadata from Milvus\\ncol = Collection(\"medical_knowledge_base_v1\")\\nexisting = col.query(expr=\"\", output_fields=[\"source\"], limit=100000)\\nalready_uploaded_sources = {row[\"source\"] for row in existing}\\n\\n# filter out docs whose source PDF is already in Milvus\\nnew_docs = [doc for doc in docs if doc.metadata[\"source\"] not in already_uploaded_sources]\\nprint(f\"🛡  Skipping {len(docs) - len(new_docs)} pages already uploaded\")\\nprint(f\"🔄  Will re-chunk {len(new_docs)} new pages\")'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# query existing 'source' metadata from Milvus\n",
    "col = Collection(\"medical_knowledge_base_v1\")\n",
    "existing = col.query(expr=\"\", output_fields=[\"source\"], limit=100000)\n",
    "already_uploaded_sources = {row[\"source\"] for row in existing}\n",
    "\n",
    "# filter out docs whose source PDF is already in Milvus\n",
    "new_docs = [doc for doc in docs if doc.metadata[\"source\"] not in already_uploaded_sources]\n",
    "print(f\"🛡  Skipping {len(docs) - len(new_docs)} pages already uploaded\")\n",
    "print(f\"🔄  Will re-chunk {len(new_docs)} new pages\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "763c62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄  20091 chunks ready for ingestion\n"
     ]
    }
   ],
   "source": [
    "# re-chunk only new pages\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(new_docs)\n",
    "print(f\"🔄  {len(chunks)} chunks ready for ingestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3471a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created new collection 'medical_knowledge_base_v1' with 20091 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Hugging Face embedder\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "try:\n",
    "    # Try to connect to an existing Milvus collection\n",
    "    vector_store = Milvus(\n",
    "        embedding_function=embedder,\n",
    "        collection_name=collection_name,\n",
    "        connection_args={\"host\": \"localhost\", \"port\": \"19530\"}\n",
    "    )\n",
    "    vector_store.add_documents(chunks)\n",
    "    print(f\"✅ Added {len(chunks)} chunks to existing collection '{collection_name}'.\")\n",
    "except Exception:\n",
    "    # If collection doesn't exist, create it and insert\n",
    "    vector_store = Milvus.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedder,\n",
    "        collection_name=collection_name,\n",
    "        connection_args={\"host\": \"localhost\", \"port\": \"19530\"}\n",
    "    )\n",
    "    print(f\"✅ Created new collection '{collection_name}' with {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "75950d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total vectors stored: 20000\n"
     ]
    }
   ],
   "source": [
    "# Confirm total stored vectors\n",
    "collection = Collection(\"medical_knowledge_base_v1\")\n",
    "print(\"✅ Total vectors stored:\", collection.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee6f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed PDFs:\n",
      " - 1-s2.0-S0720048X23000712-main.pdf\n",
      " - CT and MRI of the Whole Body, 2-Volume Set, 6e, Volume I ( PDFDrive ).pdf\n",
      " - Diagnostic Categories _ RADS - Reporting and Data Systems Support.pdf\n",
      " - Diagnostic Imaging Genitourinary ( PDFDrive ).pdf\n",
      " - Diagnostic Imaging_ Abdomen_ Published by Amirsys® ( PDFDrive ).pdf\n",
      " - Diagnostic Imaging_ Gastrointestinal ( PDFDrive ).pdf\n",
      " - Gastrointestinal Imaging_ The Requisites (Requisites in Radiology) 3rd ed ( PDFDrive ).pdf\n",
      " - Genitourinary Radiology_ Radiology Requisites Series ( PDFDrive ) (1).pdf\n",
      " - Getting Started _ RADS - Reporting and Data Systems Support.pdf\n",
      " - Imaging Features _ RADS - Reporting and Data Systems Support.pdf\n",
      " - LI-RADS 2018 Core.pdf\n",
      " - LI-RADS CTMR Nonradiation TRA v2024 Core.pdf\n",
      " - LI-RADS CTMR Radiation TRA v2024 Core.pdf\n",
      " - LI-RADS US Surveillance v2024 Core.pdf\n",
      " - LIRADS Lexicon Table.pdf\n",
      " - Liver imaging _ MRI with CT correlation ( PDFDrive ).pdf\n",
      " - Management _ RADS - Reporting and Data Systems Support.pdf\n",
      " - Mayo Clinic Gastrointestinal Imaging Review ( PDFDrive ).pdf\n",
      " - PIRADS V2-1.pdf\n",
      " - Radiology Illustrated_ Hepatobiliary and Pancreatic Radiology ( PDFDrive ).pdf\n",
      " - Reporting _ RADS - Reporting and Data Systems Support.pdf\n",
      " - Treatment Response _ RADS - Reporting and Data Systems Support.pdf\n",
      " - prostatemri2.pdf\n",
      " - s00261-019-02302-x.pdf\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: name of PDFs processed INTO milvus\n",
    "results = collection.query(expr=\"\", output_fields=[\"source\"], limit=16_384)\n",
    "pdfs = sorted({r[\"source\"] for r in results})\n",
    "print(\"Processed PDFs:\")\n",
    "for pdf in pdfs:\n",
    "    print(\" -\", pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b9d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
